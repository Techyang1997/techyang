<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Nifi安装(Mac版)</title>
    <url>/techyang/2024/09/08/Nifi%E5%AE%89%E8%A3%85-Mac%E7%89%88/</url>
    <content><![CDATA[<blockquote>
<p>下载安装Nifi包</p>
</blockquote>
<p>网址:<a href="https://archive.apache.org/dist/nifi/1.9.2/">https://archive.apache.org/dist/nifi/1.9.2/</a></p>
<p>下载的版本是1.9.2的</p>
<p>下载完成后进行解压缩</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">tar -zxvf nifi-1.9.2-bin.tar.gz -C /Users/qixiangyang/module</span><br></pre></td></tr></table></figure>

<ul>
<li>nifi-1.9.2-bin.tar.gz : 下载的tar包</li>
<li>/Users/qixiangyang/module : 解压后的路径</li>
</ul>
<blockquote>
<p>修改默认端口(默认8080)</p>
</blockquote>
<p>文件:/Users/qixiangyang/module/nifi-1.9.2/conf/nifi.properties</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">vim /Users/qixiangyang/module/nifi-1.9.2/conf/nifi.properties</span><br></pre></td></tr></table></figure>

<figure class="highlight properties"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Licensed to the Apache Software Foundation (ASF) under one or more</span></span><br><span class="line"><span class="comment"># contributor license agreements.  See the NOTICE file distributed with</span></span><br><span class="line"><span class="comment"># this work for additional information regarding copyright ownership.</span></span><br><span class="line"><span class="comment"># The ASF licenses this file to You under the Apache License, Version 2.0</span></span><br><span class="line"><span class="comment"># (the &quot;License&quot;); you may not use this file except in compliance with</span></span><br><span class="line"><span class="comment"># the License.  You may obtain a copy of the License at</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment">#     http://www.apache.org/licenses/LICENSE-2.0</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># Unless required by applicable law or agreed to in writing, software</span></span><br><span class="line"><span class="comment"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span></span><br><span class="line"><span class="comment"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span></span><br><span class="line"><span class="comment"># See the License for the specific language governing permissions and</span></span><br><span class="line"><span class="comment"># limitations under the License.</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"># Core Properties #</span></span><br><span class="line"><span class="meta">nifi.flow.configuration.file</span>=<span class="string">./conf/flow.xml.gz</span></span><br><span class="line"><span class="meta">nifi.flow.configuration.archive.enabled</span>=<span class="string">true</span></span><br><span class="line"><span class="meta">nifi.flow.configuration.archive.dir</span>=<span class="string">./conf/archive/</span></span><br><span class="line"><span class="meta">nifi.flow.configuration.archive.max.time</span>=<span class="string">30 days</span></span><br><span class="line"><span class="meta">nifi.flow.configuration.archive.max.storage</span>=<span class="string">500 MB</span></span><br><span class="line"><span class="meta">nifi.flow.configuration.archive.max.count</span>=<span class="string"></span></span><br><span class="line"><span class="meta">nifi.flowcontroller.autoResumeState</span>=<span class="string">true</span></span><br><span class="line"><span class="meta">nifi.flowcontroller.graceful.shutdown.period</span>=<span class="string">10 sec</span></span><br><span class="line"><span class="meta">nifi.flowservice.writedelay.interval</span>=<span class="string">500 ms</span></span><br><span class="line"><span class="meta">nifi.administrative.yield.duration</span>=<span class="string">30 sec</span></span><br><span class="line"><span class="comment"># If a component has no work to do (is &quot;bored&quot;), how long should we wait before checking again for work?</span></span><br><span class="line"><span class="meta">nifi.bored.yield.duration</span>=<span class="string">10 millis</span></span><br><span class="line"><span class="meta">nifi.queue.backpressure.count</span>=<span class="string">10000</span></span><br><span class="line"><span class="meta">nifi.queue.backpressure.size</span>=<span class="string">1 GB</span></span><br><span class="line"></span><br><span class="line"><span class="meta">nifi.authorizer.configuration.file</span>=<span class="string">./conf/authorizers.xml</span></span><br><span class="line"><span class="meta">nifi.login.identity.provider.configuration.file</span>=<span class="string">./conf/login-identity-providers.xml</span></span><br><span class="line"><span class="meta">nifi.templates.directory</span>=<span class="string">./conf/templates</span></span><br><span class="line"><span class="meta">nifi.ui.banner.text</span>=<span class="string"></span></span><br><span class="line"><span class="meta">nifi.ui.autorefresh.interval</span>=<span class="string">30 sec</span></span><br><span class="line"><span class="meta">nifi.nar.library.directory</span>=<span class="string">./lib</span></span><br><span class="line"><span class="meta">nifi.nar.library.autoload.directory</span>=<span class="string">./extensions</span></span><br><span class="line"><span class="meta">nifi.nar.working.directory</span>=<span class="string">./work/nar/</span></span><br><span class="line"><span class="meta">nifi.documentation.working.directory</span>=<span class="string">./work/docs/components</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">####################</span></span><br><span class="line"><span class="comment"># State Management #</span></span><br><span class="line"><span class="comment">####################</span></span><br><span class="line"><span class="meta">nifi.state.management.configuration.file</span>=<span class="string">./conf/state-management.xml</span></span><br><span class="line"><span class="comment"># The ID of the local state provider</span></span><br><span class="line"><span class="meta">nifi.state.management.provider.local</span>=<span class="string">local-provider</span></span><br><span class="line"><span class="comment"># The ID of the cluster-wide state provider. This will be ignored if NiFi is not clustered but must be populated if running in a cluster.</span></span><br><span class="line"><span class="meta">nifi.state.management.provider.cluster</span>=<span class="string">zk-provider</span></span><br><span class="line"><span class="comment"># Specifies whether or not this instance of NiFi should run an embedded ZooKeeper server</span></span><br><span class="line"><span class="meta">nifi.state.management.embedded.zookeeper.start</span>=<span class="string">false</span></span><br><span class="line"><span class="comment"># Properties file that provides the ZooKeeper properties to use if &lt;nifi.state.management.embedded.zookeeper.start&gt; is set to true</span></span><br><span class="line"><span class="meta">nifi.state.management.embedded.zookeeper.properties</span>=<span class="string">./conf/zookeeper.properties</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"># H2 Settings</span></span><br><span class="line"><span class="meta">nifi.database.directory</span>=<span class="string">./database_repository</span></span><br><span class="line"><span class="meta">nifi.h2.url.append</span>=<span class="string">;LOCK_TIMEOUT=25000;WRITE_DELAY=0;AUTO_SERVER=FALSE</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"># FlowFile Repository</span></span><br><span class="line"><span class="meta">nifi.flowfile.repository.implementation</span>=<span class="string">org.apache.nifi.controller.repository.WriteAheadFlowFileRepository</span></span><br><span class="line"><span class="meta">nifi.flowfile.repository.wal.implementation</span>=<span class="string">org.apache.nifi.wali.SequentialAccessWriteAheadLog</span></span><br><span class="line"><span class="meta">nifi.flowfile.repository.directory</span>=<span class="string">./flowfile_repository</span></span><br><span class="line"><span class="meta">nifi.flowfile.repository.partitions</span>=<span class="string">256</span></span><br><span class="line"><span class="meta">nifi.flowfile.repository.checkpoint.interval</span>=<span class="string">2 mins</span></span><br><span class="line"><span class="meta">nifi.flowfile.repository.always.sync</span>=<span class="string">false</span></span><br><span class="line"></span><br><span class="line"><span class="meta">nifi.swap.manager.implementation</span>=<span class="string">org.apache.nifi.controller.FileSystemSwapManager</span></span><br><span class="line"><span class="meta">nifi.queue.swap.threshold</span>=<span class="string">20000</span></span><br><span class="line"><span class="meta">nifi.swap.in.period</span>=<span class="string">5 sec</span></span><br><span class="line"><span class="meta">nifi.swap.in.threads</span>=<span class="string">1</span></span><br><span class="line"><span class="meta">nifi.swap.out.period</span>=<span class="string">5 sec</span></span><br><span class="line"><span class="meta">nifi.swap.out.threads</span>=<span class="string">4</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"># Content Repository</span></span><br><span class="line"><span class="meta">nifi.content.repository.implementation</span>=<span class="string">org.apache.nifi.controller.repository.FileSystemRepository</span></span><br><span class="line"><span class="meta">nifi.content.claim.max.appendable.size</span>=<span class="string">1 MB</span></span><br><span class="line"><span class="meta">nifi.content.claim.max.flow.files</span>=<span class="string">100</span></span><br><span class="line"><span class="meta">nifi.content.repository.directory.default</span>=<span class="string">./content_repository</span></span><br><span class="line"><span class="meta">nifi.content.repository.archive.max.retention.period</span>=<span class="string">12 hours</span></span><br><span class="line"><span class="meta">nifi.content.repository.archive.max.usage.percentage</span>=<span class="string">50%</span></span><br><span class="line"><span class="meta">nifi.content.repository.archive.enabled</span>=<span class="string">true</span></span><br><span class="line"><span class="meta">nifi.content.repository.always.sync</span>=<span class="string">false</span></span><br><span class="line"><span class="meta">nifi.content.viewer.url</span>=<span class="string">../nifi-content-viewer/</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"># Provenance Repository Properties</span></span><br><span class="line"><span class="meta">nifi.provenance.repository.implementation</span>=<span class="string">org.apache.nifi.provenance.WriteAheadProvenanceRepository</span></span><br><span class="line"><span class="meta">nifi.provenance.repository.debug.frequency</span>=<span class="string">1_000_000</span></span><br><span class="line"><span class="meta">nifi.provenance.repository.encryption.key.provider.implementation</span>=<span class="string"></span></span><br><span class="line"><span class="meta">nifi.provenance.repository.encryption.key.provider.location</span>=<span class="string"></span></span><br><span class="line"><span class="meta">nifi.provenance.repository.encryption.key.id</span>=<span class="string"></span></span><br><span class="line"><span class="meta">nifi.provenance.repository.encryption.key</span>=<span class="string"></span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"># Persistent Provenance Repository Properties</span></span><br><span class="line"><span class="meta">nifi.provenance.repository.directory.default</span>=<span class="string">./provenance_repository</span></span><br><span class="line"><span class="meta">nifi.provenance.repository.max.storage.time</span>=<span class="string">24 hours</span></span><br><span class="line"><span class="meta">nifi.provenance.repository.max.storage.size</span>=<span class="string">1 GB</span></span><br><span class="line"><span class="meta">nifi.provenance.repository.rollover.time</span>=<span class="string">30 secs</span></span><br><span class="line"><span class="meta">nifi.provenance.repository.rollover.size</span>=<span class="string">100 MB</span></span><br><span class="line"><span class="meta">nifi.provenance.repository.query.threads</span>=<span class="string">2</span></span><br><span class="line"><span class="meta">nifi.provenance.repository.index.threads</span>=<span class="string">2</span></span><br><span class="line"><span class="meta">nifi.provenance.repository.compress.on.rollover</span>=<span class="string">true</span></span><br><span class="line"><span class="meta">nifi.provenance.repository.always.sync</span>=<span class="string">false</span></span><br><span class="line"><span class="comment"># Comma-separated list of fields. Fields that are not indexed will not be searchable. Valid fields are:</span></span><br><span class="line"><span class="comment"># EventType, FlowFileUUID, Filename, TransitURI, ProcessorID, AlternateIdentifierURI, Relationship, Details</span></span><br><span class="line"><span class="meta">nifi.provenance.repository.indexed.fields</span>=<span class="string">EventType, FlowFileUUID, Filename, ProcessorID, Relationship</span></span><br><span class="line"><span class="comment"># FlowFile Attributes that should be indexed and made searchable.  Some examples to consider are filename, uuid, mime.type</span></span><br><span class="line"><span class="meta">nifi.provenance.repository.indexed.attributes</span>=<span class="string"></span></span><br><span class="line"><span class="comment"># Large values for the shard size will result in more Java heap usage when searching the Provenance Repository</span></span><br><span class="line"><span class="comment"># but should provide better performance</span></span><br><span class="line"><span class="meta">nifi.provenance.repository.index.shard.size</span>=<span class="string">500 MB</span></span><br><span class="line"><span class="comment"># Indicates the maximum length that a FlowFile attribute can be when retrieving a Provenance Event from</span></span><br><span class="line"><span class="comment"># the repository. If the length of any attribute exceeds this value, it will be truncated when the event is retrieved.</span></span><br><span class="line"><span class="meta">nifi.provenance.repository.max.attribute.length</span>=<span class="string">65536</span></span><br><span class="line"><span class="meta">nifi.provenance.repository.concurrent.merge.threads</span>=<span class="string">2</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"># Volatile Provenance Respository Properties</span></span><br><span class="line"><span class="meta">nifi.provenance.repository.buffer.size</span>=<span class="string">100000</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"># Component Status Repository</span></span><br><span class="line"><span class="meta">nifi.components.status.repository.implementation</span>=<span class="string">org.apache.nifi.controller.status.history.VolatileComponentStatusRepository</span></span><br><span class="line"><span class="meta">nifi.components.status.repository.buffer.size</span>=<span class="string">1440</span></span><br><span class="line"><span class="meta">nifi.components.status.snapshot.frequency</span>=<span class="string">1 min</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"># Site to Site properties</span></span><br><span class="line"><span class="meta">nifi.remote.input.host</span>=<span class="string"></span></span><br><span class="line"><span class="meta">nifi.remote.input.secure</span>=<span class="string">false</span></span><br><span class="line"><span class="meta">nifi.remote.input.socket.port</span>=<span class="string"></span></span><br><span class="line"><span class="meta">nifi.remote.input.http.enabled</span>=<span class="string">true</span></span><br><span class="line"><span class="meta">nifi.remote.input.http.transaction.ttl</span>=<span class="string">30 sec</span></span><br><span class="line"><span class="meta">nifi.remote.contents.cache.expiration</span>=<span class="string">30 secs</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"># web properties #</span></span><br><span class="line"><span class="meta">nifi.web.war.directory</span>=<span class="string">./lib</span></span><br><span class="line"><span class="meta">nifi.web.http.host</span>=<span class="string"></span></span><br><span class="line"><span class="meta">nifi.web.http.port</span>=<span class="string">5800</span></span><br><span class="line"><span class="meta">nifi.web.http.network.interface.default</span>=<span class="string"></span></span><br><span class="line"><span class="meta">nifi.web.https.host</span>=<span class="string"></span></span><br><span class="line"><span class="meta">nifi.web.https.port</span>=<span class="string"></span></span><br><span class="line"><span class="meta">nifi.web.https.network.interface.default</span>=<span class="string"></span></span><br><span class="line"><span class="meta">nifi.web.jetty.working.directory</span>=<span class="string">./work/jetty</span></span><br><span class="line"><span class="meta">nifi.web.jetty.threads</span>=<span class="string">200</span></span><br><span class="line"><span class="meta">nifi.web.max.header.size</span>=<span class="string">16 KB</span></span><br><span class="line"><span class="meta">nifi.web.proxy.context.path</span>=<span class="string"></span></span><br><span class="line"><span class="meta">nifi.web.proxy.host</span>=<span class="string"></span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"># security properties #</span></span><br><span class="line"><span class="meta">nifi.sensitive.props.key</span>=<span class="string"></span></span><br><span class="line"><span class="meta">nifi.sensitive.props.key.protected</span>=<span class="string"></span></span><br><span class="line"><span class="meta">nifi.sensitive.props.algorithm</span>=<span class="string">PBEWITHMD5AND256BITAES-CBC-OPENSSL</span></span><br><span class="line"><span class="meta">nifi.sensitive.props.provider</span>=<span class="string">BC</span></span><br><span class="line"><span class="meta">nifi.sensitive.props.additional.keys</span>=<span class="string"></span></span><br><span class="line"></span><br><span class="line"><span class="meta">nifi.security.keystore</span>=<span class="string"></span></span><br><span class="line"><span class="meta">nifi.security.keystoreType</span>=<span class="string"></span></span><br><span class="line"><span class="meta">nifi.security.keystorePasswd</span>=<span class="string"></span></span><br><span class="line"><span class="meta">nifi.security.keyPasswd</span>=<span class="string"></span></span><br><span class="line"><span class="meta">nifi.security.truststore</span>=<span class="string"></span></span><br><span class="line"><span class="meta">nifi.security.truststoreType</span>=<span class="string"></span></span><br><span class="line"><span class="meta">nifi.security.truststorePasswd</span>=<span class="string"></span></span><br><span class="line"><span class="meta">nifi.security.user.authorizer</span>=<span class="string">managed-authorizer</span></span><br><span class="line"><span class="meta">nifi.security.user.login.identity.provider</span>=<span class="string"></span></span><br><span class="line"><span class="meta">nifi.security.ocsp.responder.url</span>=<span class="string"></span></span><br><span class="line"><span class="meta">nifi.security.ocsp.responder.certificate</span>=<span class="string"></span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"># OpenId Connect SSO Properties #</span></span><br><span class="line"><span class="meta">nifi.security.user.oidc.discovery.url</span>=<span class="string"></span></span><br><span class="line"><span class="meta">nifi.security.user.oidc.connect.timeout</span>=<span class="string">5 secs</span></span><br><span class="line"><span class="meta">nifi.security.user.oidc.read.timeout</span>=<span class="string">5 secs</span></span><br><span class="line"><span class="meta">nifi.security.user.oidc.client.id</span>=<span class="string"></span></span><br><span class="line"><span class="meta">nifi.security.user.oidc.client.secret</span>=<span class="string"></span></span><br><span class="line"><span class="meta">nifi.security.user.oidc.preferred.jwsalgorithm</span>=<span class="string"></span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"># Apache Knox SSO Properties #</span></span><br><span class="line"><span class="meta">nifi.security.user.knox.url</span>=<span class="string"></span></span><br><span class="line"><span class="meta">nifi.security.user.knox.publicKey</span>=<span class="string"></span></span><br><span class="line"><span class="meta">nifi.security.user.knox.cookieName</span>=<span class="string">hadoop-jwt</span></span><br><span class="line"><span class="meta">nifi.security.user.knox.audiences</span>=<span class="string"></span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"># Identity Mapping Properties #</span></span><br><span class="line"><span class="comment"># These properties allow normalizing user identities such that identities coming from different identity providers</span></span><br><span class="line"><span class="comment"># (certificates, LDAP, Kerberos) can be treated the same internally in NiFi. The following example demonstrates normalizing</span></span><br><span class="line"><span class="comment"># DNs from certificates and principals from Kerberos into a common identity string:</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># nifi.security.identity.mapping.pattern.dn=^CN=(.*?), OU=(.*?), O=(.*?), L=(.*?), ST=(.*?), C=(.*?)$</span></span><br><span class="line"><span class="comment"># nifi.security.identity.mapping.value.dn=$1@$2</span></span><br><span class="line"><span class="comment"># nifi.security.identity.mapping.transform.dn=NONE</span></span><br><span class="line"><span class="comment"># nifi.security.identity.mapping.pattern.kerb=^(.*?)/instance@(.*?)$</span></span><br><span class="line"><span class="comment"># nifi.security.identity.mapping.value.kerb=$1@$2</span></span><br><span class="line"><span class="comment"># nifi.security.identity.mapping.transform.kerb=UPPER</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"># Group Mapping Properties #</span></span><br><span class="line"><span class="comment"># These properties allow normalizing group names coming from external sources like LDAP. The following example</span></span><br><span class="line"><span class="comment"># lowercases any group name.</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># nifi.security.group.mapping.pattern.anygroup=^(.*)$</span></span><br><span class="line"><span class="comment"># nifi.security.group.mapping.value.anygroup=$1</span></span><br><span class="line"><span class="comment"># nifi.security.group.mapping.transform.anygroup=LOWER</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"># cluster common properties (all nodes must have same values) #</span></span><br><span class="line"><span class="meta">nifi.cluster.protocol.heartbeat.interval</span>=<span class="string">5 sec</span></span><br><span class="line"><span class="meta">nifi.cluster.protocol.is.secure</span>=<span class="string">false</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"># cluster node properties (only configure for cluster nodes) #</span></span><br><span class="line"><span class="meta">nifi.cluster.is.node</span>=<span class="string">false</span></span><br><span class="line"><span class="meta">nifi.cluster.node.address</span>=<span class="string"></span></span><br><span class="line"><span class="meta">nifi.cluster.node.protocol.port</span>=<span class="string"></span></span><br><span class="line"><span class="meta">nifi.cluster.node.protocol.threads</span>=<span class="string">10</span></span><br><span class="line"><span class="meta">nifi.cluster.node.protocol.max.threads</span>=<span class="string">50</span></span><br><span class="line"><span class="meta">nifi.cluster.node.event.history.size</span>=<span class="string">25</span></span><br><span class="line"><span class="meta">nifi.cluster.node.connection.timeout</span>=<span class="string">5 sec</span></span><br><span class="line"><span class="meta">nifi.cluster.node.read.timeout</span>=<span class="string">5 sec</span></span><br><span class="line"><span class="meta">nifi.cluster.node.max.concurrent.requests</span>=<span class="string">100</span></span><br><span class="line"><span class="meta">nifi.cluster.firewall.file</span>=<span class="string"></span></span><br><span class="line"><span class="meta">nifi.cluster.flow.election.max.wait.time</span>=<span class="string">5 mins</span></span><br><span class="line"><span class="meta">nifi.cluster.flow.election.max.candidates</span>=<span class="string"></span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"># cluster load balancing properties #</span></span><br><span class="line"><span class="meta">nifi.cluster.load.balance.host</span>=<span class="string"></span></span><br><span class="line"><span class="meta">nifi.cluster.load.balance.port</span>=<span class="string">6342</span></span><br><span class="line"><span class="meta">nifi.cluster.load.balance.connections.per.node</span>=<span class="string">4</span></span><br><span class="line"><span class="meta">nifi.cluster.load.balance.max.thread.count</span>=<span class="string">8</span></span><br><span class="line"><span class="meta">nifi.cluster.load.balance.comms.timeout</span>=<span class="string">30 sec</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"># zookeeper properties, used for cluster management #</span></span><br><span class="line"><span class="meta">nifi.zookeeper.connect.string</span>=<span class="string"></span></span><br><span class="line"><span class="meta">nifi.zookeeper.connect.timeout</span>=<span class="string">3 secs</span></span><br><span class="line"><span class="meta">nifi.zookeeper.session.timeout</span>=<span class="string">3 secs</span></span><br><span class="line"><span class="meta">nifi.zookeeper.root.node</span>=<span class="string">/nifi</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"># Zookeeper properties for the authentication scheme used when creating acls on znodes used for cluster management</span></span><br><span class="line"><span class="comment"># Values supported for nifi.zookeeper.auth.type are &quot;default&quot;, which will apply world/anyone rights on znodes</span></span><br><span class="line"><span class="comment"># and &quot;sasl&quot; which will give rights to the sasl/kerberos identity used to authenticate the nifi node</span></span><br><span class="line"><span class="comment"># The identity is determined using the value in nifi.kerberos.service.principal and the removeHostFromPrincipal</span></span><br><span class="line"><span class="comment"># and removeRealmFromPrincipal values (which should align with the kerberos.removeHostFromPrincipal and kerberos.removeRealmFromPrincipal</span></span><br><span class="line"><span class="comment"># values configured on the zookeeper server).</span></span><br><span class="line"><span class="meta">nifi.zookeeper.auth.type</span>=<span class="string"></span></span><br><span class="line"><span class="meta">nifi.zookeeper.kerberos.removeHostFromPrincipal</span>=<span class="string"></span></span><br><span class="line"><span class="meta">nifi.zookeeper.kerberos.removeRealmFromPrincipal</span>=<span class="string"></span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"># kerberos #</span></span><br><span class="line"><span class="meta">nifi.kerberos.krb5.file</span>=<span class="string"></span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"># kerberos service principal #</span></span><br><span class="line"><span class="meta">nifi.kerberos.service.principal</span>=<span class="string"></span></span><br><span class="line"><span class="meta">nifi.kerberos.service.keytab.location</span>=<span class="string"></span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"># kerberos spnego principal #</span></span><br><span class="line"><span class="meta">nifi.kerberos.spnego.principal</span>=<span class="string"></span></span><br><span class="line"><span class="meta">nifi.kerberos.spnego.keytab.location</span>=<span class="string"></span></span><br><span class="line"><span class="meta">nifi.kerberos.spnego.authentication.expiration</span>=<span class="string">12 hours</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"># external properties files for variable registry</span></span><br><span class="line"><span class="comment"># supports a comma delimited list of file locations</span></span><br><span class="line"><span class="meta">nifi.variable.registry.properties</span>=<span class="string"></span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>nifi.web.http.port=8080 —&gt; nifi.web.http.port=5800</p>
<blockquote>
<p>启动Nifi</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">bin/nifi.sh start</span><br></pre></td></tr></table></figure>

<blockquote>
<p>查看页面</p>
</blockquote>
<p><a href="http://127.0.0.1:5800/nifi/">http://127.0.0.1:5800/nifi/</a></p>
<p><img src="https://techyang-blog-pic.oss-cn-beijing.aliyuncs.com/img/image-20240908091509403.png" alt="image-20240908091509403"></p>
]]></content>
      <categories>
        <category>组件</category>
      </categories>
      <tags>
        <tag>Nifi</tag>
      </tags>
  </entry>
  <entry>
    <title>SQL练习题(持续更新中...)</title>
    <url>/techyang/2024/09/20/SQL%E7%BB%83%E4%B9%A0%E9%A2%98(%E6%8C%81%E7%BB%AD%E6%9B%B4%E6%96%B0%E4%B8%AD...)/</url>
    <content><![CDATA[<p> </p>
]]></content>
      <categories>
        <category>hive</category>
      </categories>
      <tags>
        <tag>SQL</tag>
      </tags>
  </entry>
  <entry>
    <title>DataX的oracleWriter支持upsert</title>
    <url>/techyang/2024/09/09/DataX%E7%9A%84oracleWriter%E6%94%AF%E6%8C%81upsert/</url>
    <content><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>​        公司需要将处理后的数据同步到oracle数据库中,想要达到的效果是有则更新,无则插入.但dataX的oracleWriter是不支持writeMode参数的,故需要对源码进行修改使其支持.</p>
<h2 id="实现原理"><a href="#实现原理" class="headerlink" title="实现原理"></a>实现原理</h2><p>Oracle不支持类似 MySQL的 <code>REPLACE INTO</code> 和 <code>INSERT … ON DUPLICATE KEY UPDATE</code>，所以只支持 insert 配置项。要实现此功能，需要利用 Oracle 的 merge 语句，先来看下 merge 语法。</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">MERGE</span> <span class="keyword">INTO</span> [target<span class="operator">-</span><span class="keyword">table</span>] A <span class="keyword">USING</span> [source<span class="operator">-</span><span class="keyword">table</span> <span class="keyword">sql</span>] B </span><br><span class="line"><span class="keyword">ON</span>([conditional expression] <span class="keyword">and</span> [...]...) </span><br><span class="line"><span class="keyword">WHEN</span> MATCHED <span class="keyword">THEN</span></span><br><span class="line"> [UPDATE <span class="keyword">sql</span>] </span><br><span class="line"><span class="keyword">WHEN</span> <span class="keyword">NOT</span> MATCHED <span class="keyword">THEN</span> </span><br><span class="line"> [<span class="keyword">INSERT</span> <span class="keyword">sql</span>]</span><br></pre></td></tr></table></figure>

<h2 id="修改过程"><a href="#修改过程" class="headerlink" title="修改过程"></a>修改过程</h2><h3 id="第一步-下载源码"><a href="#第一步-下载源码" class="headerlink" title="第一步:下载源码"></a>第一步:下载源码</h3><p><a href="https://github.com/alibaba/DataX/releases/tag/datax_v202309">datax_v202309</a></p>
<h3 id="第二步-导入IDEA-保证编译不报错"><a href="#第二步-导入IDEA-保证编译不报错" class="headerlink" title="第二步:导入IDEA,保证编译不报错"></a>第二步:导入IDEA,保证编译不报错</h3><p>编译过程需要调整的地方:</p>
<ul>
<li><p>找不到eigenbase-properties包</p>
<p>将<a href="https://techyang-blog-pic.oss-cn-beijing.aliyuncs.com/other/eigenbase-properties-1.1.4.jar">eigenbase-properties-1.1.4.jar</a>和<a href="https://techyang-blog-pic.oss-cn-beijing.aliyuncs.com/other/eigenbase-properties-1.1.4.pom">eigenbase-properties-1.1.4.pom</a>放在本地仓库的./eigenbase/eigenbase-properties/1.1.4路径下</p>
</li>
<li><p>修改hdfsreader 模块中pom文件</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.parquet<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>parquet-format<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.4.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure></li>
<li><p>检查oceanbasev10writer 模块pom文件</p>
<p>./DataX-master/oceanbasev10writer/src/main/lib 下是否有shade-ob-partition-calculator-1.0-SNAPSHOT.jar包,没有需要到<a href="https://github.com/alibaba/DataX/tree/master/oceanbasev10writer/src/main/libs">官网</a>下载并放在该目录下</p>
</li>
</ul>
<h3 id="第三步-修改源码"><a href="#第三步-修改源码" class="headerlink" title="第三步:修改源码"></a>第三步:修改源码</h3><ul>
<li><p>Oraclewriter.java</p>
<p><img src="https://techyang-blog-pic.oss-cn-beijing.aliyuncs.com/img/image-20240909215138068.png" alt="image-20240909215138068"></p>
<p>将对应校验注释掉</p>
</li>
<li><p>WriterUtil.java</p>
<ul>
<li><p>修改getWriteTemplate方法</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> String <span class="title">getWriteTemplate</span><span class="params">(List&lt;String&gt; columnHolders, List&lt;String&gt; valueHolders, String writeMode, DataBaseType dataBaseType, <span class="keyword">boolean</span> forceUseUpdate)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">boolean</span> update = writeMode.trim().toLowerCase().startsWith(<span class="string">&quot;update&quot;</span>);</span><br><span class="line">        <span class="keyword">boolean</span> isWriteModeLegal = writeMode.trim().toLowerCase().startsWith(<span class="string">&quot;insert&quot;</span>)</span><br><span class="line">                || writeMode.trim().toLowerCase().startsWith(<span class="string">&quot;replace&quot;</span>)</span><br><span class="line">                || update;</span><br><span class="line"> </span><br><span class="line">        <span class="keyword">if</span> (!isWriteModeLegal) &#123;</span><br><span class="line">            <span class="keyword">throw</span> DataXException.asDataXException(DBUtilErrorCode.ILLEGAL_VALUE,</span><br><span class="line">                    String.format(<span class="string">&quot;您所配置的 writeMode:%s 错误. 因为DataX 目前仅支持replace,update 或 insert 方式. 请检查您的配置并作出修改.&quot;</span>, writeMode));</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// &amp;&amp; writeMode.trim().toLowerCase().startsWith(&quot;replace&quot;)</span></span><br><span class="line">        String writeDataSqlTemplate;</span><br><span class="line">        <span class="keyword">if</span> (forceUseUpdate || update) &#123;</span><br><span class="line">            <span class="comment">//update只在mysql下使用</span></span><br><span class="line">            <span class="keyword">if</span> (dataBaseType == DataBaseType.MySql || dataBaseType == DataBaseType.Tddl) &#123;</span><br><span class="line">                writeDataSqlTemplate = <span class="keyword">new</span> StringBuilder()</span><br><span class="line">                        .append(<span class="string">&quot;INSERT INTO %s (&quot;</span>).append(StringUtils.join(columnHolders, <span class="string">&quot;,&quot;</span>))</span><br><span class="line">                        .append(<span class="string">&quot;) VALUES(&quot;</span>).append(StringUtils.join(valueHolders, <span class="string">&quot;,&quot;</span>))</span><br><span class="line">                        .append(<span class="string">&quot;)&quot;</span>)</span><br><span class="line">                        .append(onDuplicateKeyUpdateString(columnHolders))</span><br><span class="line">                        .toString();</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">//update在Oracle下使用</span></span><br><span class="line">            <span class="keyword">else</span> <span class="keyword">if</span> (dataBaseType == DataBaseType.Oracle) &#123;</span><br><span class="line">                writeDataSqlTemplate = onMergeIntoDoString(writeMode, columnHolders, valueHolders) + <span class="string">&quot;INSERT (&quot;</span> +</span><br><span class="line">                        StringUtils.join(columnHolders, <span class="string">&quot;,&quot;</span>) +</span><br><span class="line">                        <span class="string">&quot;) VALUES(&quot;</span> + StringUtils.join(valueHolders, <span class="string">&quot;,&quot;</span>) +<span class="string">&quot;)&quot;</span>;</span><br><span class="line">            &#125;<span class="keyword">else</span> &#123;</span><br><span class="line">                <span class="keyword">throw</span> DataXException.asDataXException(DBUtilErrorCode.ILLEGAL_VALUE,</span><br><span class="line">                        String.format(<span class="string">&quot;当前数据库不支持 writeMode:%s 模式.&quot;</span>, writeMode));</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line"> </span><br><span class="line">            <span class="comment">//这里是保护,如果其他错误的使用了update,需要更换为replace</span></span><br><span class="line">            <span class="keyword">if</span> (update) &#123;</span><br><span class="line">                writeMode = <span class="string">&quot;replace&quot;</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            writeDataSqlTemplate = <span class="keyword">new</span> StringBuilder().append(writeMode)</span><br><span class="line">                    .append(<span class="string">&quot; INTO %s (&quot;</span>).append(StringUtils.join(columnHolders, <span class="string">&quot;,&quot;</span>))</span><br><span class="line">                    .append(<span class="string">&quot;) VALUES(&quot;</span>).append(StringUtils.join(valueHolders, <span class="string">&quot;,&quot;</span>))</span><br><span class="line">                    .append(<span class="string">&quot;)&quot;</span>).toString();</span><br><span class="line">        &#125;</span><br><span class="line"> </span><br><span class="line">        <span class="keyword">return</span> writeDataSqlTemplate;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure></li>
<li><p>新增onMergeIntoDoString与getStrings方法</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> String <span class="title">onMergeIntoDoString</span><span class="params">(String merge, List&lt;String&gt; columnHolders, List&lt;String&gt; valueHolders)</span> </span>&#123;</span><br><span class="line">        String[] sArray = getStrings(merge);</span><br><span class="line">        StringBuilder sb = <span class="keyword">new</span> StringBuilder();</span><br><span class="line">        sb.append(<span class="string">&quot;MERGE INTO %s A USING ( SELECT &quot;</span>);</span><br><span class="line">        <span class="keyword">boolean</span> first = <span class="keyword">true</span>;</span><br><span class="line">        <span class="keyword">boolean</span> first1 = <span class="keyword">true</span>;</span><br><span class="line">        StringBuilder str = <span class="keyword">new</span> StringBuilder();</span><br><span class="line">        StringBuilder update = <span class="keyword">new</span> StringBuilder();</span><br><span class="line">        <span class="keyword">for</span> (String columnHolder : columnHolders) &#123;</span><br><span class="line">            <span class="keyword">if</span> (Arrays.asList(sArray).contains(columnHolder)) &#123;</span><br><span class="line">                <span class="keyword">if</span> (!first) &#123;</span><br><span class="line">                    sb.append(<span class="string">&quot;,&quot;</span>);</span><br><span class="line">                    str.append(<span class="string">&quot; AND &quot;</span>);</span><br><span class="line">                &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                    first = <span class="keyword">false</span>;</span><br><span class="line">                &#125;</span><br><span class="line">                str.append(<span class="string">&quot;TMP.&quot;</span>).append(columnHolder);</span><br><span class="line">                sb.append(<span class="string">&quot;?&quot;</span>);</span><br><span class="line">                str.append(<span class="string">&quot; = &quot;</span>);</span><br><span class="line">                sb.append(<span class="string">&quot; AS &quot;</span>);</span><br><span class="line">                str.append(<span class="string">&quot;A.&quot;</span>).append(columnHolder);</span><br><span class="line">                sb.append(columnHolder);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"> </span><br><span class="line">        <span class="keyword">for</span> (String columnHolder : columnHolders) &#123;</span><br><span class="line">            <span class="keyword">if</span> (!Arrays.asList(sArray).contains(columnHolder)) &#123;</span><br><span class="line">                <span class="keyword">if</span> (!first1) &#123;</span><br><span class="line">                    update.append(<span class="string">&quot;,&quot;</span>);</span><br><span class="line">                &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                    first1 = <span class="keyword">false</span>;</span><br><span class="line">                &#125;</span><br><span class="line">                update.append(columnHolder);</span><br><span class="line">                update.append(<span class="string">&quot; = &quot;</span>);</span><br><span class="line">                update.append(<span class="string">&quot;?&quot;</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"> </span><br><span class="line">        sb.append(<span class="string">&quot; FROM DUAL ) TMP ON (&quot;</span>);</span><br><span class="line">        sb.append(str);</span><br><span class="line">        sb.append(<span class="string">&quot; ) WHEN MATCHED THEN UPDATE SET &quot;</span>);</span><br><span class="line">        sb.append(update);</span><br><span class="line">        sb.append(<span class="string">&quot; WHEN NOT MATCHED THEN &quot;</span>);</span><br><span class="line">        <span class="keyword">return</span> sb.toString();</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> String[] getStrings(String merge) &#123;</span><br><span class="line">        merge = merge.replace(<span class="string">&quot;update&quot;</span>, <span class="string">&quot;&quot;</span>);</span><br><span class="line">        merge = merge.replace(<span class="string">&quot;(&quot;</span>, <span class="string">&quot;&quot;</span>);</span><br><span class="line">        merge = merge.replace(<span class="string">&quot;)&quot;</span>, <span class="string">&quot;&quot;</span>);</span><br><span class="line">        merge = merge.replace(<span class="string">&quot; &quot;</span>, <span class="string">&quot;&quot;</span>);</span><br><span class="line">        <span class="keyword">return</span> merge.split(<span class="string">&quot;,&quot;</span>);</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li><p>CommonRdbmsWriter.java</p>
<ul>
<li><p>修改startWriteWithConnection</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 替换原先的代码块</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">startWriteWithConnection</span><span class="params">(RecordReceiver recordReceiver, TaskPluginCollector taskPluginCollector, Connection connection)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">this</span>.taskPluginCollector = taskPluginCollector;</span><br><span class="line">    List&lt;String&gt; columns = <span class="keyword">new</span> LinkedList&lt;&gt;();</span><br><span class="line">    <span class="keyword">if</span> (<span class="keyword">this</span>.dataBaseType == DataBaseType.Oracle &amp;&amp; writeMode.trim().toLowerCase().startsWith(<span class="string">&quot;update&quot;</span>) ) &#123;</span><br><span class="line">        String merge = <span class="keyword">this</span>.writeMode;</span><br><span class="line">        String[] sArray = WriterUtil.getStrings(merge);</span><br><span class="line">        <span class="keyword">this</span>.columns.forEach(column-&gt;&#123;</span><br><span class="line">            <span class="keyword">if</span> (Arrays.asList(sArray).contains(column)) &#123;</span><br><span class="line">                columns.add(column);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">        <span class="keyword">this</span>.columns.forEach(column-&gt;&#123;</span><br><span class="line">            <span class="keyword">if</span> (!Arrays.asList(sArray).contains(column)) &#123;</span><br><span class="line">                columns.add(column);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">    &#125;</span><br><span class="line">    columns.addAll(<span class="keyword">this</span>.columns);</span><br><span class="line">    <span class="comment">// 用于写入数据的时候的类型根据目的表字段类型转换</span></span><br><span class="line">    <span class="keyword">this</span>.resultSetMetaData = DBUtil.getColumnMetaData(connection, <span class="keyword">this</span>.table, StringUtils.join(columns, <span class="string">&quot;,&quot;</span>));</span><br><span class="line">    <span class="comment">// 写数据库的SQL语句</span></span><br><span class="line">    calcWriteRecordSql();</span><br><span class="line">     </span><br><span class="line">    List&lt;Record&gt; writeBuffer = <span class="keyword">new</span> ArrayList&lt;Record&gt;(<span class="keyword">this</span>.batchSize);</span><br><span class="line">    <span class="keyword">int</span> bufferBytes = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        Record record;</span><br><span class="line">        <span class="keyword">while</span> ((record = recordReceiver.getFromReader()) != <span class="keyword">null</span>) &#123;</span><br><span class="line">            <span class="keyword">if</span> (record.getColumnNumber() != <span class="keyword">this</span>.columnNumber) &#123;</span><br><span class="line">                <span class="comment">// 源头读取字段列数与目的表字段写入列数不相等，直接报错</span></span><br><span class="line">                <span class="keyword">throw</span> DataXException</span><br><span class="line">                        .asDataXException(</span><br><span class="line">                                DBUtilErrorCode.CONF_ERROR,</span><br><span class="line">                                String.format(</span><br><span class="line">                                        <span class="string">&quot;列配置信息有错误. 因为您配置的任务中，源头读取字段数:%s 与 目的表要写入的字段数:%s 不相等. 请检查您的配置并作出修改.&quot;</span>,</span><br><span class="line">                                        record.getColumnNumber(),</span><br><span class="line">                                        <span class="keyword">this</span>.columnNumber));</span><br><span class="line">            &#125;</span><br><span class="line">     </span><br><span class="line">            writeBuffer.add(record);</span><br><span class="line">            bufferBytes += record.getMemorySize();</span><br><span class="line">     </span><br><span class="line">            <span class="keyword">if</span> (writeBuffer.size() &gt;= batchSize || bufferBytes &gt;= batchByteSize) &#123;</span><br><span class="line">                doBatchInsert(connection, writeBuffer);</span><br><span class="line">                writeBuffer.clear();</span><br><span class="line">                bufferBytes = <span class="number">0</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (!writeBuffer.isEmpty()) &#123;</span><br><span class="line">            doBatchInsert(connection, writeBuffer);</span><br><span class="line">            writeBuffer.clear();</span><br><span class="line">            bufferBytes = <span class="number">0</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">        <span class="keyword">throw</span> DataXException.asDataXException(</span><br><span class="line">                DBUtilErrorCode.WRITE_DATA_ERROR, e);</span><br><span class="line">    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">        writeBuffer.clear();</span><br><span class="line">        bufferBytes = <span class="number">0</span>;</span><br><span class="line">        DBUtil.closeDBResources(<span class="keyword">null</span>, <span class="keyword">null</span>, connection);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li><p>修改doBatchInsert</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">doBatchInsert</span><span class="params">(Connection connection, List&lt;Record&gt; buffer)</span></span></span><br><span class="line"><span class="function">               <span class="keyword">throws</span> SQLException</span></span><br><span class="line"><span class="function">       </span>&#123;</span><br><span class="line">           PreparedStatement preparedStatement = <span class="keyword">null</span>;</span><br><span class="line">           <span class="keyword">try</span> &#123;</span><br><span class="line">               connection.setAutoCommit(<span class="keyword">false</span>);</span><br><span class="line">               preparedStatement = connection</span><br><span class="line">                       .prepareStatement(<span class="keyword">this</span>.writeRecordSql);</span><br><span class="line">               <span class="keyword">if</span> (<span class="keyword">this</span>.dataBaseType == DataBaseType.Oracle &amp;&amp; !<span class="string">&quot;insert&quot;</span>.equalsIgnoreCase(<span class="keyword">this</span>.writeMode)) &#123;</span><br><span class="line">                   String merge = <span class="keyword">this</span>.writeMode;</span><br><span class="line">                   String[] sArray = WriterUtil.getStrings(merge);</span><br><span class="line">                   <span class="keyword">for</span> (Record record : buffer) &#123;</span><br><span class="line">                       List&lt;Column&gt; recordOne = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">                       <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; <span class="keyword">this</span>.columns.size(); j++) &#123;</span><br><span class="line">                           <span class="keyword">if</span> (Arrays.asList(sArray).contains(<span class="keyword">this</span>.columns.get(j))) &#123;</span><br><span class="line">                               recordOne.add(record.getColumn(j));</span><br><span class="line">                           &#125;</span><br><span class="line">                       &#125;</span><br><span class="line">                       <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; <span class="keyword">this</span>.columns.size(); j++) &#123;</span><br><span class="line">                           <span class="keyword">if</span> (!Arrays.asList(sArray).contains(<span class="keyword">this</span>.columns.get(j))) &#123;</span><br><span class="line">                               recordOne.add(record.getColumn(j));</span><br><span class="line">                           &#125;</span><br><span class="line">                       &#125;</span><br><span class="line">                       <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; <span class="keyword">this</span>.columns.size(); j++) &#123;</span><br><span class="line">                           recordOne.add(record.getColumn(j));</span><br><span class="line">                       &#125;</span><br><span class="line">                       <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; recordOne.size(); j++) &#123;</span><br><span class="line">                           record.setColumn(j, recordOne.get(j));</span><br><span class="line">                       &#125;</span><br><span class="line">                       preparedStatement = fillPreparedStatement(</span><br><span class="line">                               preparedStatement, record);</span><br><span class="line">                       preparedStatement.addBatch();</span><br><span class="line">                   &#125;</span><br><span class="line">               &#125;</span><br><span class="line">               <span class="keyword">else</span> &#123;</span><br><span class="line">                   <span class="keyword">for</span> (Record record : buffer) &#123;</span><br><span class="line">                       preparedStatement = fillPreparedStatement(</span><br><span class="line">                               preparedStatement, record);</span><br><span class="line">                       preparedStatement.addBatch();</span><br><span class="line">                   &#125;</span><br><span class="line">               &#125;</span><br><span class="line">               preparedStatement.executeBatch();</span><br><span class="line">               connection.commit();</span><br><span class="line">           &#125;</span><br><span class="line">           <span class="keyword">catch</span> (SQLException e) &#123;</span><br><span class="line">               LOG.warn(<span class="string">&quot;回滚此次写入, 采用每次写入一行方式提交. 因为: &#123;&#125;&quot;</span>, e.getMessage());</span><br><span class="line">               connection.rollback();</span><br><span class="line">               doOneInsert(connection, buffer);</span><br><span class="line">           &#125;</span><br><span class="line">           <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">               <span class="keyword">throw</span> DataXException.asDataXException(</span><br><span class="line">                       DBUtilErrorCode.WRITE_DATA_ERROR, e);</span><br><span class="line">           &#125;</span><br><span class="line">           <span class="keyword">finally</span> &#123;</span><br><span class="line">               DBUtil.closeDBResources(preparedStatement, <span class="keyword">null</span>);</span><br><span class="line">           &#125;</span><br><span class="line">       &#125;</span><br></pre></td></tr></table></figure></li>
<li><p>修改fillPreparedStatement</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">protected</span> PreparedStatement <span class="title">fillPreparedStatement</span><span class="params">(PreparedStatement preparedStatement, Record record)</span></span></span><br><span class="line"><span class="function">              <span class="keyword">throws</span> SQLException</span></span><br><span class="line"><span class="function">      </span>&#123;</span><br><span class="line">          <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; record.getColumnNumber(); i++) &#123;</span><br><span class="line">              <span class="keyword">int</span> columnSqltype = <span class="keyword">this</span>.resultSetMetaData.getMiddle().get(i);</span><br><span class="line">              String typeName = <span class="keyword">this</span>.resultSetMetaData.getRight().get(i);</span><br><span class="line">              preparedStatement = fillPreparedStatementColumnType(preparedStatement, i,columnSqltype, typeName,record.getColumn(i));</span><br><span class="line">          &#125;</span><br><span class="line">          <span class="keyword">return</span> preparedStatement;</span><br><span class="line">      &#125;</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
</ul>
<h3 id="第四步-打包替换"><a href="#第四步-打包替换" class="headerlink" title="第四步:打包替换"></a>第四步:打包替换</h3><p>只需要在idea里面打包修改的两个程序就可以</p>
<p><img src="https://techyang-blog-pic.oss-cn-beijing.aliyuncs.com/img/image-20240909215239399.png" alt="image-20240909215239399"></p>
<p>打包成功后获取两个jar包</p>
<p><img src="https://techyang-blog-pic.oss-cn-beijing.aliyuncs.com/img/image-20240909215412625.png" alt="image-20240909215412625"></p>
<p>将包替换到datax的插件里面</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">将oraclewriter-0.0.1-SNAPSHOT.jar替换到datax\plugin\writer\oraclewriter</span><br><span class="line">将plugin-rdbms-util-0.0.1-SNAPSHOT.jar替换到datax\plugin\writer\oraclewriter\libs</span><br></pre></td></tr></table></figure>

<h2 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h2><figure class="highlight json"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">&quot;job&quot;</span>: &#123;</span><br><span class="line">        <span class="attr">&quot;setting&quot;</span>: &#123;</span><br><span class="line">            <span class="attr">&quot;speed&quot;</span>: &#123;</span><br><span class="line">                <span class="attr">&quot;channel&quot;</span>: <span class="number">1</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="attr">&quot;content&quot;</span>: [</span><br><span class="line">            &#123;</span><br><span class="line">                 <span class="attr">&quot;reader&quot;</span>: &#123;</span><br><span class="line">                    <span class="attr">&quot;name&quot;</span>: <span class="string">&quot;streamreader&quot;</span>,</span><br><span class="line">                    <span class="attr">&quot;parameter&quot;</span>: &#123;</span><br><span class="line">                        <span class="attr">&quot;column&quot;</span> : [</span><br><span class="line">                            &#123;</span><br><span class="line">                                <span class="attr">&quot;value&quot;</span>: <span class="string">&quot;DataX&quot;</span>,</span><br><span class="line">                                <span class="attr">&quot;type&quot;</span>: <span class="string">&quot;string&quot;</span></span><br><span class="line">                            &#125;,</span><br><span class="line">                            &#123;</span><br><span class="line">                                <span class="attr">&quot;value&quot;</span>: <span class="number">19880808</span>,</span><br><span class="line">                                <span class="attr">&quot;type&quot;</span>: <span class="string">&quot;long&quot;</span></span><br><span class="line">                            &#125;,</span><br><span class="line">                            &#123;</span><br><span class="line">                                <span class="attr">&quot;value&quot;</span>: <span class="string">&quot;1988-08-08 08:08:08&quot;</span>,</span><br><span class="line">                                <span class="attr">&quot;type&quot;</span>: <span class="string">&quot;date&quot;</span></span><br><span class="line">                            &#125;,</span><br><span class="line">                            &#123;</span><br><span class="line">                                <span class="attr">&quot;value&quot;</span>: <span class="literal">true</span>,</span><br><span class="line">                                <span class="attr">&quot;type&quot;</span>: <span class="string">&quot;bool&quot;</span></span><br><span class="line">                            &#125;,</span><br><span class="line">                            &#123;</span><br><span class="line">                                <span class="attr">&quot;value&quot;</span>: <span class="string">&quot;test&quot;</span>,</span><br><span class="line">                                <span class="attr">&quot;type&quot;</span>: <span class="string">&quot;bytes&quot;</span></span><br><span class="line">                            &#125;</span><br><span class="line">                        ],</span><br><span class="line">                        <span class="attr">&quot;sliceRecordCount&quot;</span>: <span class="number">1000</span></span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;,</span><br><span class="line">                <span class="attr">&quot;writer&quot;</span>: &#123;</span><br><span class="line">                    <span class="attr">&quot;name&quot;</span>: <span class="string">&quot;oraclewriter&quot;</span>,</span><br><span class="line">                    <span class="attr">&quot;parameter&quot;</span>: &#123;</span><br><span class="line">                      	<span class="attr">&quot;writeMode&quot;</span>: <span class="string">&quot;update(pk1,pk2)&quot;</span>,</span><br><span class="line">                        <span class="attr">&quot;username&quot;</span>: <span class="string">&quot;root&quot;</span>,</span><br><span class="line">                        <span class="attr">&quot;password&quot;</span>: <span class="string">&quot;root&quot;</span>,</span><br><span class="line">                        <span class="attr">&quot;column&quot;</span>: [</span><br><span class="line">                            <span class="string">&quot;id&quot;</span>,</span><br><span class="line">                            <span class="string">&quot;name&quot;</span></span><br><span class="line">                        ],</span><br><span class="line">                        <span class="attr">&quot;preSql&quot;</span>: [</span><br><span class="line">                            <span class="string">&quot;delete from test&quot;</span></span><br><span class="line">                        ],</span><br><span class="line">                        <span class="attr">&quot;connection&quot;</span>: [</span><br><span class="line">                            &#123;</span><br><span class="line">                                <span class="attr">&quot;jdbcUrl&quot;</span>: <span class="string">&quot;jdbc:oracle:thin:@[HOST_NAME]:PORT:[DATABASE_NAME]&quot;</span>,</span><br><span class="line">                                <span class="attr">&quot;table&quot;</span>: [</span><br><span class="line">                                    <span class="string">&quot;test&quot;</span></span><br><span class="line">                                ]</span><br><span class="line">                            &#125;</span><br><span class="line">                        ]</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        ]</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>参数 “writeMode”: “update(pk1,pk2)” 里面pk1,pk2就是主键</p>
]]></content>
      <categories>
        <category>DataX</category>
      </categories>
      <tags>
        <tag>oracleWriter</tag>
      </tags>
  </entry>
  <entry>
    <title>从零到一搭建离线数仓之采集篇</title>
    <url>/techyang/2024/09/07/%E4%BB%8E%E9%9B%B6%E5%88%B0%E4%B8%80%E6%90%AD%E5%BB%BA%E7%A6%BB%E7%BA%BF%E6%95%B0%E4%BB%93%E4%B9%8B%E9%87%87%E9%9B%86%E7%AF%87/</url>
    <content><![CDATA[<ul>
<li><p>前置工作:服务器间的免密已完成.</p>
</li>
<li><p>安装常用工具包</p>
</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">yum install -y epel-release</span><br><span class="line">yum install -y net-tools vim psmisc  nc  rsync  lrzsz  ntp libzstd openssl-static iotop pdsh</span><br></pre></td></tr></table></figure>

<ul>
<li>编写分发脚本</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#!/bin/bash</span><br><span class="line"> </span><br><span class="line">#1. 判断参数个数</span><br><span class="line">if [ $# -lt 1 ]</span><br><span class="line">then</span><br><span class="line">  echo Not Enough Arguement!</span><br><span class="line">  exit;</span><br><span class="line">fi</span><br><span class="line"> </span><br><span class="line">#2. 遍历集群所有机器</span><br><span class="line">for host in bigdata101 bigdata102 bigdata103 bigdata104 bigdata105</span><br><span class="line">do</span><br><span class="line">  echo ====================  $host  ====================</span><br><span class="line">  #3. 遍历所有目录，挨个发送</span><br><span class="line">  for file in $@</span><br><span class="line">  do</span><br><span class="line">    #4 判断文件是否存在</span><br><span class="line">    if [ -e $file ]</span><br><span class="line">    then</span><br><span class="line">      #5. 获取父目录</span><br><span class="line">      pdir=$(cd -P $(dirname $file); pwd)</span><br><span class="line">      #6. 获取当前文件的名称</span><br><span class="line">      fname=$(basename $file)</span><br><span class="line">      ssh $host &quot;mkdir -p $pdir&quot;</span><br><span class="line">      rsync -av $pdir/$fname $host:$pdir</span><br><span class="line">    else</span><br><span class="line">      echo $file does not exists!</span><br><span class="line">    fi</span><br><span class="line">  done</span><br><span class="line">done</span><br></pre></td></tr></table></figure>

<p>优化版(可以指定分发的机器)</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#1. 判断参数个数</span></span><br><span class="line"><span class="keyword">if</span> [ <span class="variable">$#</span> -lt 2 ]</span><br><span class="line"><span class="keyword">then</span></span><br><span class="line">  <span class="built_in">echo</span> Not Enough Arguement!</span><br><span class="line">  <span class="built_in">exit</span>;</span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化变量</span></span><br><span class="line">hosts=()</span><br><span class="line">directories=()</span><br><span class="line">separator=0</span><br><span class="line"></span><br><span class="line"><span class="comment"># 遍历所有参数</span></span><br><span class="line"><span class="keyword">for</span> arg <span class="keyword">in</span> <span class="string">&quot;<span class="variable">$@</span>&quot;</span></span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">  <span class="keyword">if</span> [[ -d <span class="string">&quot;<span class="variable">$arg</span>&quot;</span> ]]; <span class="keyword">then</span></span><br><span class="line">      separator=1</span><br><span class="line">  <span class="keyword">fi</span></span><br><span class="line">  <span class="keyword">if</span> [[ -f <span class="string">&quot;<span class="variable">$arg</span>&quot;</span> ]]; <span class="keyword">then</span></span><br><span class="line">      separator=1</span><br><span class="line">  <span class="keyword">fi</span></span><br><span class="line">  <span class="keyword">if</span> [[ <span class="variable">$separator</span> -eq 0 ]]; <span class="keyword">then</span></span><br><span class="line">      hosts+=(<span class="string">&quot;<span class="variable">$arg</span>&quot;</span>)</span><br><span class="line">  <span class="keyword">else</span></span><br><span class="line">      directories+=(<span class="string">&quot;<span class="variable">$arg</span>&quot;</span>)</span><br><span class="line">  <span class="keyword">fi</span></span><br><span class="line"><span class="keyword">done</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#2. 遍历集群所有机器</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="string">&quot;<span class="variable">$&#123;!hosts[@]&#125;</span>&quot;</span></span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">  host=<span class="variable">$&#123;hosts[$i]&#125;</span></span><br><span class="line">  <span class="built_in">echo</span> ====================  <span class="variable">$host</span>  ====================</span><br><span class="line">  <span class="comment">#3. 遍历所有目录，挨个发送</span></span><br><span class="line">  <span class="keyword">for</span> j <span class="keyword">in</span> <span class="string">&quot;<span class="variable">$&#123;!directories[@]&#125;</span>&quot;</span></span><br><span class="line">  <span class="keyword">do</span></span><br><span class="line">    file=<span class="variable">$&#123;directories[$j]&#125;</span></span><br><span class="line">    <span class="comment">#4 判断文件是否存在</span></span><br><span class="line">    <span class="keyword">if</span> [ -e <span class="variable">$file</span> ]</span><br><span class="line">    <span class="keyword">then</span></span><br><span class="line">      <span class="comment">#5. 获取父目录</span></span><br><span class="line">      pdir=$(<span class="built_in">cd</span> -P $(dirname <span class="variable">$file</span>); <span class="built_in">pwd</span>)</span><br><span class="line">      <span class="comment">#6. 获取当前文件的名称</span></span><br><span class="line">      fname=$(basename <span class="variable">$file</span>)</span><br><span class="line">      ssh <span class="variable">$host</span> <span class="string">&quot;mkdir -p <span class="variable">$pdir</span>&quot;</span></span><br><span class="line">      rsync -av <span class="variable">$pdir</span>/<span class="variable">$fname</span> <span class="variable">$host</span>:<span class="variable">$pdir</span></span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">      <span class="built_in">echo</span> <span class="variable">$file</span> does not exists!</span><br><span class="line">    <span class="keyword">fi</span></span><br><span class="line">  <span class="keyword">done</span></span><br><span class="line"><span class="keyword">done</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h2 id="一-集群规划"><a href="#一-集群规划" class="headerlink" title="一.集群规划"></a>一.集群规划</h2><table>
<thead>
<tr>
<th>bigdata101</th>
<th>bigdata102</th>
<th>bigdata103</th>
<th>bigdata104</th>
<th>bigdata105</th>
</tr>
</thead>
<tbody><tr>
<td>JDK</td>
<td>JDK</td>
<td>JDK</td>
<td>JDK</td>
<td>JDK</td>
</tr>
<tr>
<td></td>
<td></td>
<td>ZK</td>
<td>ZK</td>
<td>ZK</td>
</tr>
<tr>
<td>NN</td>
<td>NN</td>
<td>DN</td>
<td>DN</td>
<td>DN</td>
</tr>
<tr>
<td>DFSZKFC</td>
<td>DFSZKFC</td>
<td>JN</td>
<td>JN</td>
<td>JN</td>
</tr>
<tr>
<td>RM</td>
<td>RM</td>
<td>NM</td>
<td>NM</td>
<td>NM</td>
</tr>
<tr>
<td></td>
<td></td>
<td>KAFKA</td>
<td>KAFKA</td>
<td>KAFKA</td>
</tr>
<tr>
<td>FLUME</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>MYSQL</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>MAXWELL</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody></table>
<h2 id="二-组件安装"><a href="#二-组件安装" class="headerlink" title="二.组件安装"></a>二.组件安装</h2><h3 id="2-1-安装JDK"><a href="#2-1-安装JDK" class="headerlink" title="2.1 安装JDK"></a>2.1 安装JDK</h3><ul>
<li><p>解压缩</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">tar -zxvf /opt/software/jdk-8u212-linux-x64.tar.gz -C /opt/module/</span><br></pre></td></tr></table></figure></li>
<li><p>配置环境变量</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo vim /etc/profile.d/my_env.sh</span><br></pre></td></tr></table></figure>

<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment">#JAVA_HOME</span></span><br><span class="line"><span class="built_in">export</span> JAVA_HOME=/opt/module/jdk1.8.0_212</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$JAVA_HOME</span>/bin</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">source /etc/profile.d/my_env.sh</span><br></pre></td></tr></table></figure></li>
<li><p>验证</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">java -version</span><br></pre></td></tr></table></figure>

<p>结果:</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">java version &quot;1.8.0_212&quot;</span><br><span class="line">Java(TM) SE Runtime Environment (build 1.8.0_212-b10)</span><br><span class="line">Java HotSpot(TM) 64-Bit Server VM (build 25.212-b10, mixed mode)</span><br></pre></td></tr></table></figure></li>
<li><p>分发</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">xsync /opt/module/jdk1.8.0_212</span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="2-2-安装ZK"><a href="#2-2-安装ZK" class="headerlink" title="2.2 安装ZK"></a>2.2 安装ZK</h3><ul>
<li><p>在bigdata3服务器解压缩</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">tar -zxvf /opt/software/apache-zookeeper-3.7.1-bin.tar.gz -C /opt/module</span><br></pre></td></tr></table></figure></li>
<li><p>重命名</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mv apache-zookeeper-3.7.1-bin zookeeper-3.7.1</span><br></pre></td></tr></table></figure></li>
<li><p>在zookeeper-3.7.1目录下创建zkData</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mkdir zkData</span><br></pre></td></tr></table></figure></li>
<li><p>在zkData创建文件myid</p>
<p>在文件中添加与server对应的编号（注意：上下不要有空行，左右不要有空格）</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">vim myid</span><br></pre></td></tr></table></figure>

<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">3</span><br></pre></td></tr></table></figure></li>
<li><p>在conf目录下复制一份zoo.cfg</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cp zoo_sample.cfg zoo.cfg</span><br></pre></td></tr></table></figure></li>
<li><p>修改zoo.cfg配置</p>
<p><img src="https://techyang-blog-pic.oss-cn-beijing.aliyuncs.com/img/image-20240907170155236.png" alt="image-20240907170155236"></p>
<p>配置参数解读:</p>
<p>server.A=B:C:D</p>
<p><strong>A</strong>是一个数字，表示这个是第几号服务器；</p>
<p>集群模式下配置一个文件myid，这个文件在dataDir目录下，这个文件里面有一个数据就是A的值，Zookeeper启动时读取此文件，拿到里面的数据与zoo.cfg里面的配置信息比较从而判断到底是哪个server。</p>
<p><strong>B</strong>是这个服务器的地址；</p>
<p><strong>C</strong>是这个服务器Follower与集群中的Leader服务器交换信息的端口；</p>
<p><strong>D</strong>是万一集群中的Leader服务器挂了，需要一个端口来重新进行选举，选出一个新的Leader，而这个端口就是用来执行选举时服务器相互通信的端口。</p>
</li>
<li><p>将bigdata3的zk分发到bigdata4,bigdata5并修改对应机器的myid</p>
</li>
<li><p>zk群起群停脚本</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">case</span> <span class="variable">$1</span> <span class="keyword">in</span></span><br><span class="line"><span class="string">&quot;start&quot;</span>)&#123;</span><br><span class="line">	<span class="keyword">for</span> i <span class="keyword">in</span> bigdata103 bigdata104 bigdata105</span><br><span class="line">	<span class="keyword">do</span></span><br><span class="line">        <span class="built_in">echo</span> ---------- zookeeper <span class="variable">$i</span> 启动 ------------</span><br><span class="line">		ssh <span class="variable">$i</span> <span class="string">&quot;/opt/module/zookeeper-3.7.1/bin/zkServer.sh start&quot;</span></span><br><span class="line">	<span class="keyword">done</span></span><br><span class="line">&#125;;;</span><br><span class="line"><span class="string">&quot;stop&quot;</span>)&#123;</span><br><span class="line">	<span class="keyword">for</span> i <span class="keyword">in</span> bigdata103 bigdata104 bigdata105</span><br><span class="line">	<span class="keyword">do</span></span><br><span class="line">        <span class="built_in">echo</span> ---------- zookeeper <span class="variable">$i</span> 停止 ------------    </span><br><span class="line">		ssh <span class="variable">$i</span> <span class="string">&quot;/opt/module/zookeeper-3.7.1/bin/zkServer.sh stop&quot;</span></span><br><span class="line">	<span class="keyword">done</span></span><br><span class="line">&#125;;;</span><br><span class="line"><span class="string">&quot;status&quot;</span>)&#123;</span><br><span class="line">	<span class="keyword">for</span> i <span class="keyword">in</span> bigdata103 bigdata104 bigdata105</span><br><span class="line">	<span class="keyword">do</span></span><br><span class="line">        <span class="built_in">echo</span> ---------- zookeeper <span class="variable">$i</span> 状态 ------------    </span><br><span class="line">		ssh <span class="variable">$i</span> <span class="string">&quot;/opt/module/zookeeper-3.7.1/bin/zkServer.sh status&quot;</span></span><br><span class="line">	<span class="keyword">done</span></span><br><span class="line">&#125;;;</span><br><span class="line"><span class="keyword">esac</span></span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="2-3-安装Hadoop"><a href="#2-3-安装Hadoop" class="headerlink" title="2.3 安装Hadoop"></a>2.3 安装Hadoop</h3><ul>
<li><p>在bigdata101解压缩</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">tar -zxvf /opt/software/hadoop-3.3.4.tar.gz -C /opt/module</span><br></pre></td></tr></table></figure></li>
<li><p>配置Hadoop环境变量</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="built_in">export</span> HADOOP_HOME=/opt/module/hadoop-3.3.4</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$HADOOP_HOME</span>/bin:<span class="variable">$HADOOP_HOME</span>/sbin</span><br></pre></td></tr></table></figure></li>
<li><p>调整./etc/hadoop/hadoop-env.sh</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment">#增加java环境变量</span></span><br><span class="line"><span class="built_in">export</span> JAVA_HOME=<span class="variable">$&#123;JAVA_HOME&#125;</span></span><br></pre></td></tr></table></figure></li>
<li><p>调整./etc/hadoop/core-site.xml</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;</span></span><br><span class="line"><span class="meta">&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;</span></span><br><span class="line"><span class="comment">&lt;!--</span></span><br><span class="line"><span class="comment">  Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span></span><br><span class="line"><span class="comment">  you may not use this file except in compliance with the License.</span></span><br><span class="line"><span class="comment">  You may obtain a copy of the License at</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">    http://www.apache.org/licenses/LICENSE-2.0</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">  Unless required by applicable law or agreed to in writing, software</span></span><br><span class="line"><span class="comment">  distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span></span><br><span class="line"><span class="comment">  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span></span><br><span class="line"><span class="comment">  See the License for the specific language governing permissions and</span></span><br><span class="line"><span class="comment">  limitations under the License. See accompanying LICENSE file.</span></span><br><span class="line"><span class="comment">--&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- Put site-specific property overrides in this file. --&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 指定NameNode的地址 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://mycluster<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 指定hadoop数据的存储目录 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.tmp.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>/opt/module/hadoop-3.3.4/data<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 配置HDFS网页登录使用的静态用户为qixy --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.http.staticuser.user<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>qixy<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 配置Zookeeper信息 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>ha.zookeeper.quorum<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>bigdata103:2181,bigdata104:2181,bigdata105:2181<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 配置该user(superUser)允许通过代理访问的主机节点 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.proxyuser.user.hosts<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>*<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 配置该user(superUser)允许通过代理用户所属组 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.proxyuser.user.groups<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>*<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 配置该user(superUser)允许通过代理的用户--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.proxyuser.user.users<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>*<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--  开启hdfs的垃圾桶机制，删除掉的数据可以从垃圾桶中回收，单位分钟 7天--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.trash.interval<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>1440<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure></li>
<li><p>调整./etc/hadoop/hdfs-site.xml</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;</span></span><br><span class="line"><span class="meta">&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;</span></span><br><span class="line"><span class="comment">&lt;!--</span></span><br><span class="line"><span class="comment">  Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span></span><br><span class="line"><span class="comment">  you may not use this file except in compliance with the License.</span></span><br><span class="line"><span class="comment">  You may obtain a copy of the License at</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">    http://www.apache.org/licenses/LICENSE-2.0</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">  Unless required by applicable law or agreed to in writing, software</span></span><br><span class="line"><span class="comment">  distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span></span><br><span class="line"><span class="comment">  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span></span><br><span class="line"><span class="comment">  See the License for the specific language governing permissions and</span></span><br><span class="line"><span class="comment">  limitations under the License. See accompanying LICENSE file.</span></span><br><span class="line"><span class="comment">--&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- Put site-specific property overrides in this file. --&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- NameNode数据存储目录 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.name.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>file://$&#123;hadoop.tmp.dir&#125;/name<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!-- DataNode数据存储目录 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.datanode.data.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>file://$&#123;hadoop.tmp.dir&#125;/data<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!-- JournalNode数据存储目录 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.journalnode.edits.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>$&#123;hadoop.tmp.dir&#125;/jn<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!-- 完全分布式集群名称 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.nameservices<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>mycluster<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!-- 集群中NameNode节点都有哪些 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.ha.namenodes.mycluster<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>nn1,nn2<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!-- NameNode的RPC通信地址 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.rpc-address.mycluster.nn1<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>bigdata101:8020<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.rpc-address.mycluster.nn2<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>bigdata102:8020<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!-- NameNode的http通信地址 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.http-address.mycluster.nn1<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>bigdata101:9870<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.http-address.mycluster.nn2<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>bigdata102:9870<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!-- 指定NameNode元数据在JournalNode上的存放位置 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.shared.edits.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>qjournal://bigdata103:8485;bigdata104:8485;bigdata105:8485/mycluster<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!-- 访问代理类：client用于确定哪个NameNode为Active --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.client.failover.proxy.provider.mycluster<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!-- 配置隔离机制，即同一时刻只能有一台服务器对外响应 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.ha.fencing.methods<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>sshfence<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!-- 使用隔离机制时需要ssh秘钥登录--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.ha.fencing.ssh.private-key-files<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>/home/qixy/.ssh/id_rsa<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 启用nn故障自动转移 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.ha.automatic-failover.enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure></li>
<li><p>配置DN节点</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">vim /opt/module/hadoop-3.3.4/etc/hadoop/workers</span><br></pre></td></tr></table></figure>

<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">bigdata101</span><br><span class="line">bigdata102</span><br><span class="line">bigdata103</span><br><span class="line">bigdata104</span><br><span class="line">bigdata105</span><br></pre></td></tr></table></figure></li>
<li><p>调整./etc/hadoop/yarn-site.xml</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=&quot;1.0&quot;?&gt;</span></span><br><span class="line"><span class="comment">&lt;!--</span></span><br><span class="line"><span class="comment">  Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span></span><br><span class="line"><span class="comment">  you may not use this file except in compliance with the License.</span></span><br><span class="line"><span class="comment">  You may obtain a copy of the License at</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">    http://www.apache.org/licenses/LICENSE-2.0</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">  Unless required by applicable law or agreed to in writing, software</span></span><br><span class="line"><span class="comment">  distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span></span><br><span class="line"><span class="comment">  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span></span><br><span class="line"><span class="comment">  See the License for the specific language governing permissions and</span></span><br><span class="line"><span class="comment">  limitations under the License. See accompanying LICENSE file.</span></span><br><span class="line"><span class="comment">--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- Site specific YARN configuration properties --&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- Site specific YARN configuration properties --&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 指定 MR 走 shuffle --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>mapreduce_shuffle<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services.mapreduce.shuffle.class<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>org.apache.hadoop.mapred.ShuffleHandler<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 日志聚集功能使用 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.log-aggregation-enable<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!-- 日志保留时间设置7天 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.log-aggregation.retain-seconds<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>604800<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!-- 日志聚合HDFS目录 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.remote-app-log-dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>/data/hadoop/yarn-logs<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!-- 超时的周期 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.connect.retry-interval.ms<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>2000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 启用resourcemanager ha --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.ha.enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!-- 声明两台resourcemanager的地址 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.cluster-id<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>cluster-yarn<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!--指定resourcemanager的逻辑列表--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.ha.rm-ids<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>rm1,rm2<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- ========== rm1的配置 ========== --&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 指定rm1的主机名 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.hostname.rm1<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>bigdata101<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!-- ========== rm2的配置 ========== --&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 指定rm2的主机名 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.hostname.rm2<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>bigdata102<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!-- 指定zookeeper集群的地址 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.zk-address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>bigdata103:2181,bigdata104:2181,bigdata105:2181<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!-- 启用自动恢复 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.recovery.enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!-- 指定resourcemanager的状态信息存储在zookeeper集群 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.store.class<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!-- 环境变量的继承 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.env-whitelist<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAPRED_HOME<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure></li>
<li><p>调整./etc/hadoop/mapred-site.xml</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=&quot;1.0&quot;?&gt;</span></span><br><span class="line"><span class="meta">&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;</span></span><br><span class="line"><span class="comment">&lt;!--</span></span><br><span class="line"><span class="comment">  Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span></span><br><span class="line"><span class="comment">  you may not use this file except in compliance with the License.</span></span><br><span class="line"><span class="comment">  You may obtain a copy of the License at</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">    http://www.apache.org/licenses/LICENSE-2.0</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">  Unless required by applicable law or agreed to in writing, software</span></span><br><span class="line"><span class="comment">  distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span></span><br><span class="line"><span class="comment">  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span></span><br><span class="line"><span class="comment">  See the License for the specific language governing permissions and</span></span><br><span class="line"><span class="comment">  limitations under the License. See accompanying LICENSE file.</span></span><br><span class="line"><span class="comment">--&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- Put site-specific property overrides in this file. --&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 指定MapReduce程序运行在Yarn上 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.framework.name<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>yarn<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>bigdata101:10020<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.webapp.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>bigdata101:19888<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure></li>
<li><p>分发hadoop文件和环境变量</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">xsync /opt/module/hadoop-3.3.4</span><br></pre></td></tr></table></figure></li>
<li><p>初始化集群</p>
<p>删除错误数据</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">xcall rm -rf /opt/module/hadoop-3.3.4/data /opt/module/hadoop-3.3.4/logs</span><br></pre></td></tr></table></figure>

<p>启动JN</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">xcall -w &quot;bigdata103,bigdata104,bigdata105&quot; &#x27;hdfs --daemon start journalnode&#x27;</span><br></pre></td></tr></table></figure>

<p>初始化其中一台NN</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">xcall -w &#x27;bigdata101&#x27; &#x27;hdfs namenode -format&#x27;</span><br></pre></td></tr></table></figure>

<p>启动初始化的NN</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">xcall -w &#x27;bigdata101&#x27; &#x27;hdfs --daemon start namenode&#x27;</span><br></pre></td></tr></table></figure>

<p>同步NN到其它节点的NN</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">xcall -w &#x27;bigdata102&#x27; &#x27;hdfs namenode -bootstrapStandby&#x27;</span><br></pre></td></tr></table></figure>

<p>启动其它节点NN</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">xcall -w &#x27;bigdata102&#x27; &#x27;hdfs --daemon start namenode&#x27;</span><br></pre></td></tr></table></figure>

<p>启动ZK</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">zk.sh start</span><br></pre></td></tr></table></figure>

<p>格式化ZKFC</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">hdfs zkfc -formatZK</span><br></pre></td></tr></table></figure>

<p>启动ZKFC</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">xcall -w &#x27;bigdata101,bigdata102&#x27; &#x27;hdfs --daemon start zkfc&#x27;</span><br></pre></td></tr></table></figure>

<p>启动DN</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">hdfs --workers --daemon start datanode</span><br></pre></td></tr></table></figure>

<p>启动yarn</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">start-yarn.sh</span><br></pre></td></tr></table></figure></li>
<li><p>编写hadoop启动脚本</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="meta">#! /bin/bash</span></span><br><span class="line"><span class="keyword">if</span> [ <span class="variable">$#</span> -eq 0 ]</span><br><span class="line"><span class="keyword">then</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">&quot;没有参数,请输入&quot;</span></span><br><span class="line">        <span class="built_in">exit</span></span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"><span class="keyword">case</span> <span class="variable">$1</span> <span class="keyword">in</span></span><br><span class="line"><span class="string">&quot;start&quot;</span>)</span><br><span class="line">        <span class="built_in">echo</span> <span class="string">&quot;===========启动hdfs============&quot;</span></span><br><span class="line">         ssh bigdata101 <span class="string">&quot;/opt/module/hadoop-3.3.4/sbin/start-dfs.sh&quot;</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">&quot;===========启动yarn============&quot;</span></span><br><span class="line">         ssh bigdata101 <span class="string">&quot;/opt/module/hadoop-3.3.4/sbin/start-yarn.sh&quot;</span></span><br><span class="line">        ;;</span><br><span class="line"><span class="string">&quot;stop&quot;</span>)</span><br><span class="line">        <span class="built_in">echo</span> <span class="string">&quot;===========关闭yarn============&quot;</span></span><br><span class="line">        ssh bigdata101 <span class="string">&quot;/opt/module/hadoop-3.3.4/sbin/stop-yarn.sh&quot;</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">&quot;===========关闭hdfs============&quot;</span></span><br><span class="line">        ssh bigdata101 <span class="string">&quot;/opt/module/hadoop-3.3.4/sbin/stop-dfs.sh&quot;</span></span><br><span class="line">        ;;</span><br><span class="line">*)</span><br><span class="line">        <span class="built_in">echo</span> <span class="string">&quot;参数错误&quot;</span></span><br><span class="line">        ;;</span><br><span class="line"><span class="keyword">esac</span></span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="2-4-部署Kafka"><a href="#2-4-部署Kafka" class="headerlink" title="2.4 部署Kafka"></a>2.4 部署Kafka</h3><ul>
<li><p>在bigdata103解压缩</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">tar -zxvf /opt/software/kafka_2.12-3.3.1.tgz -C /opt/module/</span><br></pre></td></tr></table></figure></li>
<li><p>修改配置文件 cofig/server.properties</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">vim /opt/module/kafka_2.12-3.3.1/config/server.properties</span><br></pre></td></tr></table></figure>

<p>要出修改的参数</p>
<figure class="highlight properties"><table><tr><td class="code"><pre><span class="line"><span class="comment">#broker的全局唯一编号，不能重复，只能是数字。</span></span><br><span class="line"><span class="meta">broker.id</span>=<span class="string">3</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">#broker对外暴露的IP和端口 （每个节点单独配置）       </span></span><br><span class="line"><span class="meta">advertised.listeners</span>=<span class="string">PLAINTEXT://bigdata103:9092</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">#kafka运行日志(数据)存放的路径，路径不需要提前创建，kafka自动帮你创建，可以配置多个磁盘路径，路径与路径之间可以用&quot;，&quot;分隔</span></span><br><span class="line"><span class="meta">log.dirs</span>=<span class="string">/opt/module/kafka_2.12-3.3.1/datas</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">#配置连接Zookeeper集群地址（在zk根目录下创建/kafka，方便管理）</span></span><br><span class="line"><span class="meta">zookeeper.connect</span>=<span class="string">bigdata103:2181,bigdata104:2181,bigdata105:2181/kafka</span></span><br></pre></td></tr></table></figure></li>
<li><p>配置环境变量(三台)</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment">#KAFKA_HOME</span></span><br><span class="line"><span class="built_in">export</span> KAFKA_HOME=/opt/module/kafka_2.12-3.3.1</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$KAFKA_HOME</span>/bin</span><br></pre></td></tr></table></figure></li>
<li><p>分发到要部署的机器</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">xsync bigdata103 bigdata104 bigdata105 /opt/module/kafka_2.12-3.3.1</span><br></pre></td></tr></table></figure></li>
<li><p>调整每台机器上的 broker.id 和 advertised.listeners</p>
<figure class="highlight properties"><table><tr><td class="code"><pre><span class="line"><span class="comment">#bigdata104</span></span><br><span class="line"><span class="meta">broker.id</span>=<span class="string">4</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">#broker对外暴露的IP和端口 （每个节点单独配置）       </span></span><br><span class="line"><span class="meta">advertised.listeners</span>=<span class="string">PLAINTEXT://bigdata104:9092</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">#bigdata105</span></span><br><span class="line"><span class="meta">broker.id</span>=<span class="string">5</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">#broker对外暴露的IP和端口 （每个节点单独配置）       </span></span><br><span class="line"><span class="meta">advertised.listeners</span>=<span class="string">PLAINTEXT://bigdata105:9092</span></span><br></pre></td></tr></table></figure></li>
<li><p>启动脚本</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="meta">#! /bin/bash</span></span><br><span class="line"> </span><br><span class="line"><span class="keyword">case</span> <span class="variable">$1</span> <span class="keyword">in</span></span><br><span class="line"><span class="string">&quot;start&quot;</span>)&#123;</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> bigdata103 bigdata104 bigdata105</span><br><span class="line">    <span class="keyword">do</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">&quot; --------启动 <span class="variable">$i</span> Kafka-------&quot;</span></span><br><span class="line">        ssh <span class="variable">$i</span> <span class="string">&quot;/opt/module/kafka_2.12-3.3.1/bin/kafka-server-start.sh -daemon /opt/module/kafka_2.12-3.3.1/config/server.properties&quot;</span></span><br><span class="line">    <span class="keyword">done</span></span><br><span class="line">&#125;;;</span><br><span class="line"><span class="string">&quot;stop&quot;</span>)&#123;</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> bigdata103 bigdata104 bigdata105</span><br><span class="line">    <span class="keyword">do</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">&quot; --------停止 <span class="variable">$i</span> Kafka-------&quot;</span></span><br><span class="line">        ssh <span class="variable">$i</span> <span class="string">&quot;/opt/module/kafka_2.12-3.3.1/bin/kafka-server-stop.sh &quot;</span></span><br><span class="line">    <span class="keyword">done</span></span><br><span class="line">&#125;;;</span><br><span class="line"><span class="keyword">esac</span></span><br></pre></td></tr></table></figure></li>
<li><p>验证</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kf.sh start</span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="2-5-部署Flume"><a href="#2-5-部署Flume" class="headerlink" title="2.5 部署Flume"></a>2.5 部署Flume</h3><ul>
<li><p>在bigdata101解压缩</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">tar -zxvf /opt/software/apache-flume-1.10.1-bin.tar.gz -C /opt/module/</span><br></pre></td></tr></table></figure></li>
<li><p>重命名</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mv /opt/module/apache-flume-1.10.1-bin /opt/module/flume-1.10.1</span><br></pre></td></tr></table></figure></li>
<li><p>创建存放flume日志的文件夹</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mkdir /opt/module/flume-1.10.1/logs</span><br></pre></td></tr></table></figure></li>
<li><p>调整日志配置</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">vim ./config/log4j2.xml</span><br></pre></td></tr></table></figure>

<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 将.当前目录调整为新建的日志目录 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">Property</span> <span class="attr">name</span>=<span class="string">&quot;LOG_DIR&quot;</span>&gt;</span>/opt/module/flume-1.10.1/logs<span class="tag">&lt;/<span class="name">Property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 引入控制台输出，方便学习查看日志 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">Root</span> <span class="attr">level</span>=<span class="string">&quot;INFO&quot;</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">AppenderRef</span> <span class="attr">ref</span>=<span class="string">&quot;LogFile&quot;</span> /&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">AppenderRef</span> <span class="attr">ref</span>=<span class="string">&quot;Console&quot;</span> /&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">Root</span>&gt;</span></span><br></pre></td></tr></table></figure></li>
<li><p>设置环境变量</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment">#FLUME_HOME</span></span><br><span class="line"><span class="built_in">export</span> FLUME_HOME=/opt/module/flume-1.10.1</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$FLUME_HOME</span>/bin</span><br></pre></td></tr></table></figure></li>
</ul>
<p>  <strong>验证 本地文件 到 Kafka</strong></p>
<ul>
<li><p>创建文件夹</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 用于存放自定义的配置</span></span><br><span class="line">mkdir -p /opt/module/flume-1.10.1/job</span><br><span class="line"><span class="meta">#</span><span class="bash"> 用于存放追加的元数据文件</span></span><br><span class="line">mkdir -p /opt/module/flume-1.10.1/position</span><br></pre></td></tr></table></figure></li>
<li><p>在job路径下配置文件系统到kafka的配置文件(日志选择tailDirSource)</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 定义组件</span><br><span class="line">a1.sources = r1</span><br><span class="line">a1.channels = c1</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#source</span><br><span class="line">a1.sources.r1.type = TAILDIR</span><br><span class="line">a1.sources.r1.filegroups = f1</span><br><span class="line">a1.sources.r1.filegroups.f1 = /opt/module/applog/log/app.*</span><br><span class="line">a1.sources.r1.positionFile = /opt/module/flume-1.10.1/position/taildir_position.json</span><br><span class="line"></span><br><span class="line">#channel</span><br><span class="line">a1.channels.c1.type = org.apache.flume.channel.kafka.KafkaChannel</span><br><span class="line">a1.channels.c1.kafka.bootstrap.servers = bigdata103:9092,bigdata104:9092,bigdata105:9092</span><br><span class="line">a1.channels.c1.kafka.topic = topic_log</span><br><span class="line">#parseAsFlumeEvent设置为false，到kafka的内容就只包含body的了，不包含头的了</span><br><span class="line">a1.channels.c1.parseAsFlumeEvent = false</span><br><span class="line"></span><br><span class="line"># bind</span><br><span class="line">a1.sources.r1.channels = c1</span><br></pre></td></tr></table></figure></li>
<li><p>验证本地文件到Kafka的通道是否打通</p>
<blockquote>
<p>前提保证zk,kafka已启动</p>
</blockquote>
<p>启动Flume</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">flume-ng agent -c /opt/module/flume-1.10.1/conf -f /opt/module/flume-1.10.1/job/log_to_kafka.conf -n a1</span><br></pre></td></tr></table></figure>

<p>开启Kafka消费者</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kafka-console-consumer.sh --bootstrap-server bigdata103:9092 --topic topic_log</span><br></pre></td></tr></table></figure>

<p>模拟日志数据</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">java -jar gmall-remake-mock-2023-05-15-3.jar test 100</span><br></pre></td></tr></table></figure>

<p>如果看到消费者消费到了日志数据,说明通道打通.</p>
<p><img src="https://techyang-blog-pic.oss-cn-beijing.aliyuncs.com/img/image-20240908155952188.png" alt="image-20240908155952188"></p>
</li>
<li><p>封装flume启动脚本</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">!/bin/bash</span></span><br><span class="line"></span><br><span class="line">case $1 in</span><br><span class="line">&quot;start&quot;)&#123;</span><br><span class="line">    echo &quot; --------启动 bigdata101 采集flume-------&quot;</span><br><span class="line">    ssh bigdata101 &quot;nohup /opt/module/flume-1.10.1/bin/flume-ng agent -n a1 -c /opt/module/flume-1.10.1/conf/ -f /opt/module/flume-1.10.1/job/log_to_kafka.conf &gt;/dev/null 2&gt;&amp;1 &amp;&quot;</span><br><span class="line">&#125;;;</span><br><span class="line">&quot;stop&quot;)&#123;</span><br><span class="line">    echo &quot; --------停止 bigdata101 采集flume-------&quot;</span><br><span class="line">    ssh bigdata101 &quot;ps -ef | grep log_to_kafka | grep -v grep |awk  &#x27;&#123;print \$2&#125;&#x27; | xargs -n1 kill -9 &quot;</span><br><span class="line">&#125;;;</span><br><span class="line">esac</span><br></pre></td></tr></table></figure></li>
</ul>
<p><strong>将flume同步到bigdata103</strong></p>
<ul>
<li><p>在job目录下配置kafka到hdfs的配置文件(KafkaSource –&gt; fileChanel –&gt; hdfsSink)</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#定义组件</span><br><span class="line">a1.sources=r1</span><br><span class="line">a1.channels=c1</span><br><span class="line">a1.sinks=k1</span><br><span class="line"> </span><br><span class="line">#配置source1</span><br><span class="line">a1.sources.r1.type = org.apache.flume.source.kafka.KafkaSource</span><br><span class="line">#一批次5000个event</span><br><span class="line">a1.sources.r1.batchSize = 5000</span><br><span class="line">#时间超过2s</span><br><span class="line">a1.sources.r1.batchDurationMillis = 2000</span><br><span class="line">#链接kafka的机器</span><br><span class="line">a1.sources.r1.kafka.bootstrap.servers = bigdata103:9092,bigdata104:9092,bigdata105:9092</span><br><span class="line">#主题</span><br><span class="line">a1.sources.r1.kafka.topics=topic_log</span><br><span class="line">#拦截器</span><br><span class="line">a1.sources.r1.interceptors = i1</span><br><span class="line">#自己写的拦截器，功能主要是包装header的时间戳字段</span><br><span class="line">a1.sources.r1.interceptors.i1.type = com.techyang.gmall.flume.interceptor.TimestampInterceptor$Builder</span><br><span class="line"> </span><br><span class="line">#配置channel</span><br><span class="line">a1.channels.c1.type = file</span><br><span class="line">a1.channels.c1.dataDirs = /opt/module/flume-1.10.1/data/behavior</span><br><span class="line">a1.channels.c1.checkpointDir = /opt/module/flume-1.10.1/checkpoint/behavior</span><br><span class="line">a1.channels.c1.maxFileSize = 2146435071</span><br><span class="line">a1.channels.c1.capacity = 1000000</span><br><span class="line">#如果sink端处理的慢，source端处理的快，source传到channel后，channel已满，先等6s再看是否要回滚，如果有空间了不会回滚</span><br><span class="line">a1.channels.c1.keep-alive = 6</span><br><span class="line"> </span><br><span class="line">#配置sink</span><br><span class="line">a1.sinks.k1.type = hdfs</span><br><span class="line"># 通过环境变量定位到配置文件</span><br><span class="line">a1.sinks.k1.hdfs.path = /origin_data/gmall/log/topic_log/%Y-%m-%d</span><br><span class="line">a1.sinks.k1.hdfs.filePrefix = log</span><br><span class="line">a1.sinks.k1.hdfs.round = false</span><br><span class="line"> </span><br><span class="line"> #10s回滚一个新文件</span><br><span class="line">a1.sinks.k1.hdfs.rollInterval = 10</span><br><span class="line">#文件大小超过128M回滚一个新文件</span><br><span class="line">a1.sinks.k1.hdfs.rollSize = 134217728</span><br><span class="line">a1.sinks.k1.hdfs.rollCount = 0</span><br><span class="line">#控制输出文件类型</span><br><span class="line">a1.sinks.k1.hdfs.fileType = CompressedStream</span><br><span class="line">a1.sinks.k1.hdfs.codeC = gzip</span><br><span class="line"> </span><br><span class="line">#组装 </span><br><span class="line">a1.sources.r1.channels = c1</span><br><span class="line">a1.sinks.k1.channel = c1</span><br></pre></td></tr></table></figure></li>
<li><p>自定义拦截器</p>
<p>….</p>
</li>
</ul>
<h3 id="2-6-安装MySQL"><a href="#2-6-安装MySQL" class="headerlink" title="2.6 安装MySQL"></a>2.6 安装MySQL</h3><ul>
<li><p>卸载MySQL依赖</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo yum remove mysql-libs</span><br></pre></td></tr></table></figure></li>
<li><p>安装依赖</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo yum install libaio</span><br><span class="line"></span><br><span class="line">sudo yum -y install autoconf</span><br></pre></td></tr></table></figure></li>
<li><p>切换root用户,执行安装脚本</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">su root</span><br><span class="line"></span><br><span class="line">sh install_mysql.sh</span><br></pre></td></tr></table></figure></li>
<li><p>切回普通用户</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">exit</span><br></pre></td></tr></table></figure></li>
<li><p>开启MySQL的binlog</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo vim /etc/my.cfg</span><br></pre></td></tr></table></figure>

<p>在[mysqld]下增加以下内容</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#数据库id</span><br><span class="line">server-id = 1</span><br><span class="line">#启动binlog，该参数的值会作为binlog的文件名</span><br><span class="line">log-bin=mysql-bin</span><br><span class="line">#binlog类型，maxwell要求为row类型</span><br><span class="line">binlog_format=row</span><br><span class="line">#启用binlog的数据库，需根据实际情况作出修改</span><br><span class="line">binlog-do-db=gmall</span><br></pre></td></tr></table></figure>

<p>保存并重启mysql</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo systemctl restart mysqld</span><br></pre></td></tr></table></figure>

<blockquote>
<p>如果重启失败,检查 /etc/my.cfg文件是否存在问题!</p>
</blockquote>
</li>
</ul>
<h3 id="2-7-安装MaxWell"><a href="#2-7-安装MaxWell" class="headerlink" title="2.7 安装MaxWell"></a>2.7 安装MaxWell</h3><ul>
<li><p>在bigdata101解压缩</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">tar -zxvf /opt/software/maxwell-1.29.2.tar.gz -C /opt/module</span><br></pre></td></tr></table></figure></li>
<li><p>创建maxwell需要的数据库和用户</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 创建数据库</span></span><br><span class="line"><span class="keyword">CREATE</span> DATABASE maxwell;</span><br><span class="line"><span class="comment">-- 创建maxwell用户并赋予权限  用户名 maxwell 密码 maxwell</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">USER</span> <span class="string">&#x27;maxwell&#x27;</span>@<span class="string">&#x27;%&#x27;</span> IDENTIFIED <span class="keyword">BY</span> <span class="string">&#x27;maxwell&#x27;</span>;</span><br><span class="line"><span class="comment">-- 给maxwell用户赋予maxwell开头的数据库所有的权限</span></span><br><span class="line"><span class="keyword">GRANT</span> <span class="keyword">ALL</span> <span class="keyword">ON</span> maxwell.<span class="operator">*</span> <span class="keyword">TO</span> <span class="string">&#x27;maxwell&#x27;</span>@<span class="string">&#x27;%&#x27;</span>;</span><br><span class="line"><span class="comment">-- 给maxwell用户赋予 所有的数据库有查询和复制的权限</span></span><br><span class="line"><span class="keyword">GRANT</span> <span class="keyword">SELECT</span>, REPLICATION CLIENT, REPLICATION SLAVE <span class="keyword">ON</span> <span class="operator">*</span>.<span class="operator">*</span> <span class="keyword">TO</span> <span class="string">&#x27;maxwell&#x27;</span>@<span class="string">&#x27;%&#x27;</span>;</span><br></pre></td></tr></table></figure></li>
<li><p>配置maxwell</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cp config.properties.example config.properties</span><br></pre></td></tr></table></figure>

<figure class="highlight properties"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Maxwell数据发送目的地，可选配置有stdout|file|kafka|kinesis|pubsub|sqs|rabbitmq|redis</span></span><br><span class="line"><span class="attr">producer</span>=<span class="string">kafka</span></span><br><span class="line"><span class="comment"># 目标Kafka集群地址</span></span><br><span class="line"><span class="meta">kafka.bootstrap.servers</span>=<span class="string">bigdata103:9092,bigdata104:9092,bigdata105:9092</span></span><br><span class="line"><span class="comment">#目标Kafka topic，可静态配置，例如:maxwell，也可动态配置，例如：%&#123;database&#125;_%&#123;table&#125;</span></span><br><span class="line"><span class="attr">kafka_topic</span>=<span class="string">topic_db</span></span><br><span class="line"><span class="comment"> </span></span><br><span class="line"><span class="comment"># MySQL相关配置</span></span><br><span class="line"><span class="attr">host</span>=<span class="string">bigdata101</span></span><br><span class="line"><span class="attr">user</span>=<span class="string">maxwell</span></span><br><span class="line"><span class="attr">password</span>=<span class="string">maxwell</span></span><br><span class="line"><span class="attr">jdbc_options</span>=<span class="string">useSSL=false&amp;serverTimezone=Asia/Shanghai&amp;allowPublicKeyRetrieval=true</span></span><br><span class="line"><span class="comment"> </span></span><br><span class="line"><span class="comment"># 过滤gmall中的z_log表数据，该表是日志数据的备份，无须采集</span></span><br><span class="line"><span class="attr">filter</span>=<span class="string">exclude:gmall.z_log</span></span><br><span class="line"><span class="comment"># 指定数据按照主键分组进入Kafka不同分区，避免数据倾斜</span></span><br><span class="line"><span class="attr">producer_partition_by</span>=<span class="string">primary_key</span></span><br></pre></td></tr></table></figure></li>
<li><p>封装maxwell启停脚本</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"> </span><br><span class="line">MAXWELL_HOME=/opt/module/maxwell-1.29.2</span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="title">status_maxwell</span></span>()&#123;</span><br><span class="line">    result=`ps -ef | grep com.zendesk.maxwell.Maxwell | grep -v grep | wc -l`</span><br><span class="line">    <span class="built_in">return</span> <span class="variable">$result</span></span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="title">start_maxwell</span></span>()&#123;</span><br><span class="line">    status_maxwell</span><br><span class="line">    <span class="keyword">if</span> [[ $? -lt 1 ]]; <span class="keyword">then</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">&quot;启动Maxwell&quot;</span></span><br><span class="line">        <span class="variable">$MAXWELL_HOME</span>/bin/maxwell --config <span class="variable">$MAXWELL_HOME</span>/config.properties --daemon</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">&quot;Maxwell正在运行&quot;</span></span><br><span class="line">    <span class="keyword">fi</span></span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="title">stop_maxwell</span></span>()&#123;</span><br><span class="line">    status_maxwell</span><br><span class="line">    <span class="keyword">if</span> [[ $? -gt 0 ]]; <span class="keyword">then</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">&quot;停止Maxwell&quot;</span></span><br><span class="line">        ps -ef | grep com.zendesk.maxwell.Maxwell | grep -v grep | awk <span class="string">&#x27;&#123;print $2&#125;&#x27;</span> | xargs <span class="built_in">kill</span> -9</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">&quot;Maxwell未在运行&quot;</span></span><br><span class="line">    <span class="keyword">fi</span></span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"><span class="keyword">case</span> <span class="variable">$1</span> <span class="keyword">in</span></span><br><span class="line">    start )</span><br><span class="line">        start_maxwell</span><br><span class="line">    ;;</span><br><span class="line">    stop )</span><br><span class="line">        stop_maxwell</span><br><span class="line">    ;;</span><br><span class="line">    restart )</span><br><span class="line">       stop_maxwell</span><br><span class="line">       start_maxwell</span><br><span class="line">    ;;</span><br><span class="line"><span class="keyword">esac</span></span><br></pre></td></tr></table></figure></li>
<li><p>启动</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mxw.sh start</span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="2-8-安装DataX"><a href="#2-8-安装DataX" class="headerlink" title="2.8 安装DataX"></a>2.8 安装DataX</h3><ul>
<li><p>在bigdata101解压缩</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">tar -zxvf /opt/software/datax.tar.gz -C /opt/module/</span><br></pre></td></tr></table></figure></li>
<li><p>验证是否安装成功</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">python ./bin/datax.py ./job/job.json</span><br></pre></td></tr></table></figure></li>
</ul>
]]></content>
      <categories>
        <category>JAVA</category>
      </categories>
      <tags>
        <tag>离线数仓</tag>
      </tags>
  </entry>
</search>
