<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Nifi安装(Mac版)</title>
    <url>/techyang/2024/09/08/Nifi%E5%AE%89%E8%A3%85-Mac%E7%89%88/</url>
    <content><![CDATA[<blockquote>
<p>下载安装Nifi包</p>
</blockquote>
<p>网址:<a href="https://archive.apache.org/dist/nifi/1.9.2/">https://archive.apache.org/dist/nifi/1.9.2/</a></p>
<p>下载的版本是1.9.2的</p>
<p>下载完成后进行解压缩</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">tar -zxvf nifi-1.9.2-bin.tar.gz -C /Users/qixiangyang/module</span><br></pre></td></tr></table></figure>

<ul>
<li>nifi-1.9.2-bin.tar.gz : 下载的tar包</li>
<li>/Users/qixiangyang/module : 解压后的路径</li>
</ul>
<blockquote>
<p>修改默认端口(默认8080)</p>
</blockquote>
<p>文件:/Users/qixiangyang/module/nifi-1.9.2/conf/nifi.properties</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">vim /Users/qixiangyang/module/nifi-1.9.2/conf/nifi.properties</span><br></pre></td></tr></table></figure>

<figure class="highlight properties"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Licensed to the Apache Software Foundation (ASF) under one or more</span></span><br><span class="line"><span class="comment"># contributor license agreements.  See the NOTICE file distributed with</span></span><br><span class="line"><span class="comment"># this work for additional information regarding copyright ownership.</span></span><br><span class="line"><span class="comment"># The ASF licenses this file to You under the Apache License, Version 2.0</span></span><br><span class="line"><span class="comment"># (the &quot;License&quot;); you may not use this file except in compliance with</span></span><br><span class="line"><span class="comment"># the License.  You may obtain a copy of the License at</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment">#     http://www.apache.org/licenses/LICENSE-2.0</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># Unless required by applicable law or agreed to in writing, software</span></span><br><span class="line"><span class="comment"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span></span><br><span class="line"><span class="comment"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span></span><br><span class="line"><span class="comment"># See the License for the specific language governing permissions and</span></span><br><span class="line"><span class="comment"># limitations under the License.</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"># Core Properties #</span></span><br><span class="line"><span class="meta">nifi.flow.configuration.file</span>=<span class="string">./conf/flow.xml.gz</span></span><br><span class="line"><span class="meta">nifi.flow.configuration.archive.enabled</span>=<span class="string">true</span></span><br><span class="line"><span class="meta">nifi.flow.configuration.archive.dir</span>=<span class="string">./conf/archive/</span></span><br><span class="line"><span class="meta">nifi.flow.configuration.archive.max.time</span>=<span class="string">30 days</span></span><br><span class="line"><span class="meta">nifi.flow.configuration.archive.max.storage</span>=<span class="string">500 MB</span></span><br><span class="line"><span class="meta">nifi.flow.configuration.archive.max.count</span>=<span class="string"></span></span><br><span class="line"><span class="meta">nifi.flowcontroller.autoResumeState</span>=<span class="string">true</span></span><br><span class="line"><span class="meta">nifi.flowcontroller.graceful.shutdown.period</span>=<span class="string">10 sec</span></span><br><span class="line"><span class="meta">nifi.flowservice.writedelay.interval</span>=<span class="string">500 ms</span></span><br><span class="line"><span class="meta">nifi.administrative.yield.duration</span>=<span class="string">30 sec</span></span><br><span class="line"><span class="comment"># If a component has no work to do (is &quot;bored&quot;), how long should we wait before checking again for work?</span></span><br><span class="line"><span class="meta">nifi.bored.yield.duration</span>=<span class="string">10 millis</span></span><br><span class="line"><span class="meta">nifi.queue.backpressure.count</span>=<span class="string">10000</span></span><br><span class="line"><span class="meta">nifi.queue.backpressure.size</span>=<span class="string">1 GB</span></span><br><span class="line"></span><br><span class="line"><span class="meta">nifi.authorizer.configuration.file</span>=<span class="string">./conf/authorizers.xml</span></span><br><span class="line"><span class="meta">nifi.login.identity.provider.configuration.file</span>=<span class="string">./conf/login-identity-providers.xml</span></span><br><span class="line"><span class="meta">nifi.templates.directory</span>=<span class="string">./conf/templates</span></span><br><span class="line"><span class="meta">nifi.ui.banner.text</span>=<span class="string"></span></span><br><span class="line"><span class="meta">nifi.ui.autorefresh.interval</span>=<span class="string">30 sec</span></span><br><span class="line"><span class="meta">nifi.nar.library.directory</span>=<span class="string">./lib</span></span><br><span class="line"><span class="meta">nifi.nar.library.autoload.directory</span>=<span class="string">./extensions</span></span><br><span class="line"><span class="meta">nifi.nar.working.directory</span>=<span class="string">./work/nar/</span></span><br><span class="line"><span class="meta">nifi.documentation.working.directory</span>=<span class="string">./work/docs/components</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">####################</span></span><br><span class="line"><span class="comment"># State Management #</span></span><br><span class="line"><span class="comment">####################</span></span><br><span class="line"><span class="meta">nifi.state.management.configuration.file</span>=<span class="string">./conf/state-management.xml</span></span><br><span class="line"><span class="comment"># The ID of the local state provider</span></span><br><span class="line"><span class="meta">nifi.state.management.provider.local</span>=<span class="string">local-provider</span></span><br><span class="line"><span class="comment"># The ID of the cluster-wide state provider. This will be ignored if NiFi is not clustered but must be populated if running in a cluster.</span></span><br><span class="line"><span class="meta">nifi.state.management.provider.cluster</span>=<span class="string">zk-provider</span></span><br><span class="line"><span class="comment"># Specifies whether or not this instance of NiFi should run an embedded ZooKeeper server</span></span><br><span class="line"><span class="meta">nifi.state.management.embedded.zookeeper.start</span>=<span class="string">false</span></span><br><span class="line"><span class="comment"># Properties file that provides the ZooKeeper properties to use if &lt;nifi.state.management.embedded.zookeeper.start&gt; is set to true</span></span><br><span class="line"><span class="meta">nifi.state.management.embedded.zookeeper.properties</span>=<span class="string">./conf/zookeeper.properties</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"># H2 Settings</span></span><br><span class="line"><span class="meta">nifi.database.directory</span>=<span class="string">./database_repository</span></span><br><span class="line"><span class="meta">nifi.h2.url.append</span>=<span class="string">;LOCK_TIMEOUT=25000;WRITE_DELAY=0;AUTO_SERVER=FALSE</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"># FlowFile Repository</span></span><br><span class="line"><span class="meta">nifi.flowfile.repository.implementation</span>=<span class="string">org.apache.nifi.controller.repository.WriteAheadFlowFileRepository</span></span><br><span class="line"><span class="meta">nifi.flowfile.repository.wal.implementation</span>=<span class="string">org.apache.nifi.wali.SequentialAccessWriteAheadLog</span></span><br><span class="line"><span class="meta">nifi.flowfile.repository.directory</span>=<span class="string">./flowfile_repository</span></span><br><span class="line"><span class="meta">nifi.flowfile.repository.partitions</span>=<span class="string">256</span></span><br><span class="line"><span class="meta">nifi.flowfile.repository.checkpoint.interval</span>=<span class="string">2 mins</span></span><br><span class="line"><span class="meta">nifi.flowfile.repository.always.sync</span>=<span class="string">false</span></span><br><span class="line"></span><br><span class="line"><span class="meta">nifi.swap.manager.implementation</span>=<span class="string">org.apache.nifi.controller.FileSystemSwapManager</span></span><br><span class="line"><span class="meta">nifi.queue.swap.threshold</span>=<span class="string">20000</span></span><br><span class="line"><span class="meta">nifi.swap.in.period</span>=<span class="string">5 sec</span></span><br><span class="line"><span class="meta">nifi.swap.in.threads</span>=<span class="string">1</span></span><br><span class="line"><span class="meta">nifi.swap.out.period</span>=<span class="string">5 sec</span></span><br><span class="line"><span class="meta">nifi.swap.out.threads</span>=<span class="string">4</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"># Content Repository</span></span><br><span class="line"><span class="meta">nifi.content.repository.implementation</span>=<span class="string">org.apache.nifi.controller.repository.FileSystemRepository</span></span><br><span class="line"><span class="meta">nifi.content.claim.max.appendable.size</span>=<span class="string">1 MB</span></span><br><span class="line"><span class="meta">nifi.content.claim.max.flow.files</span>=<span class="string">100</span></span><br><span class="line"><span class="meta">nifi.content.repository.directory.default</span>=<span class="string">./content_repository</span></span><br><span class="line"><span class="meta">nifi.content.repository.archive.max.retention.period</span>=<span class="string">12 hours</span></span><br><span class="line"><span class="meta">nifi.content.repository.archive.max.usage.percentage</span>=<span class="string">50%</span></span><br><span class="line"><span class="meta">nifi.content.repository.archive.enabled</span>=<span class="string">true</span></span><br><span class="line"><span class="meta">nifi.content.repository.always.sync</span>=<span class="string">false</span></span><br><span class="line"><span class="meta">nifi.content.viewer.url</span>=<span class="string">../nifi-content-viewer/</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"># Provenance Repository Properties</span></span><br><span class="line"><span class="meta">nifi.provenance.repository.implementation</span>=<span class="string">org.apache.nifi.provenance.WriteAheadProvenanceRepository</span></span><br><span class="line"><span class="meta">nifi.provenance.repository.debug.frequency</span>=<span class="string">1_000_000</span></span><br><span class="line"><span class="meta">nifi.provenance.repository.encryption.key.provider.implementation</span>=<span class="string"></span></span><br><span class="line"><span class="meta">nifi.provenance.repository.encryption.key.provider.location</span>=<span class="string"></span></span><br><span class="line"><span class="meta">nifi.provenance.repository.encryption.key.id</span>=<span class="string"></span></span><br><span class="line"><span class="meta">nifi.provenance.repository.encryption.key</span>=<span class="string"></span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"># Persistent Provenance Repository Properties</span></span><br><span class="line"><span class="meta">nifi.provenance.repository.directory.default</span>=<span class="string">./provenance_repository</span></span><br><span class="line"><span class="meta">nifi.provenance.repository.max.storage.time</span>=<span class="string">24 hours</span></span><br><span class="line"><span class="meta">nifi.provenance.repository.max.storage.size</span>=<span class="string">1 GB</span></span><br><span class="line"><span class="meta">nifi.provenance.repository.rollover.time</span>=<span class="string">30 secs</span></span><br><span class="line"><span class="meta">nifi.provenance.repository.rollover.size</span>=<span class="string">100 MB</span></span><br><span class="line"><span class="meta">nifi.provenance.repository.query.threads</span>=<span class="string">2</span></span><br><span class="line"><span class="meta">nifi.provenance.repository.index.threads</span>=<span class="string">2</span></span><br><span class="line"><span class="meta">nifi.provenance.repository.compress.on.rollover</span>=<span class="string">true</span></span><br><span class="line"><span class="meta">nifi.provenance.repository.always.sync</span>=<span class="string">false</span></span><br><span class="line"><span class="comment"># Comma-separated list of fields. Fields that are not indexed will not be searchable. Valid fields are:</span></span><br><span class="line"><span class="comment"># EventType, FlowFileUUID, Filename, TransitURI, ProcessorID, AlternateIdentifierURI, Relationship, Details</span></span><br><span class="line"><span class="meta">nifi.provenance.repository.indexed.fields</span>=<span class="string">EventType, FlowFileUUID, Filename, ProcessorID, Relationship</span></span><br><span class="line"><span class="comment"># FlowFile Attributes that should be indexed and made searchable.  Some examples to consider are filename, uuid, mime.type</span></span><br><span class="line"><span class="meta">nifi.provenance.repository.indexed.attributes</span>=<span class="string"></span></span><br><span class="line"><span class="comment"># Large values for the shard size will result in more Java heap usage when searching the Provenance Repository</span></span><br><span class="line"><span class="comment"># but should provide better performance</span></span><br><span class="line"><span class="meta">nifi.provenance.repository.index.shard.size</span>=<span class="string">500 MB</span></span><br><span class="line"><span class="comment"># Indicates the maximum length that a FlowFile attribute can be when retrieving a Provenance Event from</span></span><br><span class="line"><span class="comment"># the repository. If the length of any attribute exceeds this value, it will be truncated when the event is retrieved.</span></span><br><span class="line"><span class="meta">nifi.provenance.repository.max.attribute.length</span>=<span class="string">65536</span></span><br><span class="line"><span class="meta">nifi.provenance.repository.concurrent.merge.threads</span>=<span class="string">2</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"># Volatile Provenance Respository Properties</span></span><br><span class="line"><span class="meta">nifi.provenance.repository.buffer.size</span>=<span class="string">100000</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"># Component Status Repository</span></span><br><span class="line"><span class="meta">nifi.components.status.repository.implementation</span>=<span class="string">org.apache.nifi.controller.status.history.VolatileComponentStatusRepository</span></span><br><span class="line"><span class="meta">nifi.components.status.repository.buffer.size</span>=<span class="string">1440</span></span><br><span class="line"><span class="meta">nifi.components.status.snapshot.frequency</span>=<span class="string">1 min</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"># Site to Site properties</span></span><br><span class="line"><span class="meta">nifi.remote.input.host</span>=<span class="string"></span></span><br><span class="line"><span class="meta">nifi.remote.input.secure</span>=<span class="string">false</span></span><br><span class="line"><span class="meta">nifi.remote.input.socket.port</span>=<span class="string"></span></span><br><span class="line"><span class="meta">nifi.remote.input.http.enabled</span>=<span class="string">true</span></span><br><span class="line"><span class="meta">nifi.remote.input.http.transaction.ttl</span>=<span class="string">30 sec</span></span><br><span class="line"><span class="meta">nifi.remote.contents.cache.expiration</span>=<span class="string">30 secs</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"># web properties #</span></span><br><span class="line"><span class="meta">nifi.web.war.directory</span>=<span class="string">./lib</span></span><br><span class="line"><span class="meta">nifi.web.http.host</span>=<span class="string"></span></span><br><span class="line"><span class="meta">nifi.web.http.port</span>=<span class="string">5800</span></span><br><span class="line"><span class="meta">nifi.web.http.network.interface.default</span>=<span class="string"></span></span><br><span class="line"><span class="meta">nifi.web.https.host</span>=<span class="string"></span></span><br><span class="line"><span class="meta">nifi.web.https.port</span>=<span class="string"></span></span><br><span class="line"><span class="meta">nifi.web.https.network.interface.default</span>=<span class="string"></span></span><br><span class="line"><span class="meta">nifi.web.jetty.working.directory</span>=<span class="string">./work/jetty</span></span><br><span class="line"><span class="meta">nifi.web.jetty.threads</span>=<span class="string">200</span></span><br><span class="line"><span class="meta">nifi.web.max.header.size</span>=<span class="string">16 KB</span></span><br><span class="line"><span class="meta">nifi.web.proxy.context.path</span>=<span class="string"></span></span><br><span class="line"><span class="meta">nifi.web.proxy.host</span>=<span class="string"></span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"># security properties #</span></span><br><span class="line"><span class="meta">nifi.sensitive.props.key</span>=<span class="string"></span></span><br><span class="line"><span class="meta">nifi.sensitive.props.key.protected</span>=<span class="string"></span></span><br><span class="line"><span class="meta">nifi.sensitive.props.algorithm</span>=<span class="string">PBEWITHMD5AND256BITAES-CBC-OPENSSL</span></span><br><span class="line"><span class="meta">nifi.sensitive.props.provider</span>=<span class="string">BC</span></span><br><span class="line"><span class="meta">nifi.sensitive.props.additional.keys</span>=<span class="string"></span></span><br><span class="line"></span><br><span class="line"><span class="meta">nifi.security.keystore</span>=<span class="string"></span></span><br><span class="line"><span class="meta">nifi.security.keystoreType</span>=<span class="string"></span></span><br><span class="line"><span class="meta">nifi.security.keystorePasswd</span>=<span class="string"></span></span><br><span class="line"><span class="meta">nifi.security.keyPasswd</span>=<span class="string"></span></span><br><span class="line"><span class="meta">nifi.security.truststore</span>=<span class="string"></span></span><br><span class="line"><span class="meta">nifi.security.truststoreType</span>=<span class="string"></span></span><br><span class="line"><span class="meta">nifi.security.truststorePasswd</span>=<span class="string"></span></span><br><span class="line"><span class="meta">nifi.security.user.authorizer</span>=<span class="string">managed-authorizer</span></span><br><span class="line"><span class="meta">nifi.security.user.login.identity.provider</span>=<span class="string"></span></span><br><span class="line"><span class="meta">nifi.security.ocsp.responder.url</span>=<span class="string"></span></span><br><span class="line"><span class="meta">nifi.security.ocsp.responder.certificate</span>=<span class="string"></span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"># OpenId Connect SSO Properties #</span></span><br><span class="line"><span class="meta">nifi.security.user.oidc.discovery.url</span>=<span class="string"></span></span><br><span class="line"><span class="meta">nifi.security.user.oidc.connect.timeout</span>=<span class="string">5 secs</span></span><br><span class="line"><span class="meta">nifi.security.user.oidc.read.timeout</span>=<span class="string">5 secs</span></span><br><span class="line"><span class="meta">nifi.security.user.oidc.client.id</span>=<span class="string"></span></span><br><span class="line"><span class="meta">nifi.security.user.oidc.client.secret</span>=<span class="string"></span></span><br><span class="line"><span class="meta">nifi.security.user.oidc.preferred.jwsalgorithm</span>=<span class="string"></span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"># Apache Knox SSO Properties #</span></span><br><span class="line"><span class="meta">nifi.security.user.knox.url</span>=<span class="string"></span></span><br><span class="line"><span class="meta">nifi.security.user.knox.publicKey</span>=<span class="string"></span></span><br><span class="line"><span class="meta">nifi.security.user.knox.cookieName</span>=<span class="string">hadoop-jwt</span></span><br><span class="line"><span class="meta">nifi.security.user.knox.audiences</span>=<span class="string"></span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"># Identity Mapping Properties #</span></span><br><span class="line"><span class="comment"># These properties allow normalizing user identities such that identities coming from different identity providers</span></span><br><span class="line"><span class="comment"># (certificates, LDAP, Kerberos) can be treated the same internally in NiFi. The following example demonstrates normalizing</span></span><br><span class="line"><span class="comment"># DNs from certificates and principals from Kerberos into a common identity string:</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># nifi.security.identity.mapping.pattern.dn=^CN=(.*?), OU=(.*?), O=(.*?), L=(.*?), ST=(.*?), C=(.*?)$</span></span><br><span class="line"><span class="comment"># nifi.security.identity.mapping.value.dn=$1@$2</span></span><br><span class="line"><span class="comment"># nifi.security.identity.mapping.transform.dn=NONE</span></span><br><span class="line"><span class="comment"># nifi.security.identity.mapping.pattern.kerb=^(.*?)/instance@(.*?)$</span></span><br><span class="line"><span class="comment"># nifi.security.identity.mapping.value.kerb=$1@$2</span></span><br><span class="line"><span class="comment"># nifi.security.identity.mapping.transform.kerb=UPPER</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"># Group Mapping Properties #</span></span><br><span class="line"><span class="comment"># These properties allow normalizing group names coming from external sources like LDAP. The following example</span></span><br><span class="line"><span class="comment"># lowercases any group name.</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># nifi.security.group.mapping.pattern.anygroup=^(.*)$</span></span><br><span class="line"><span class="comment"># nifi.security.group.mapping.value.anygroup=$1</span></span><br><span class="line"><span class="comment"># nifi.security.group.mapping.transform.anygroup=LOWER</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"># cluster common properties (all nodes must have same values) #</span></span><br><span class="line"><span class="meta">nifi.cluster.protocol.heartbeat.interval</span>=<span class="string">5 sec</span></span><br><span class="line"><span class="meta">nifi.cluster.protocol.is.secure</span>=<span class="string">false</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"># cluster node properties (only configure for cluster nodes) #</span></span><br><span class="line"><span class="meta">nifi.cluster.is.node</span>=<span class="string">false</span></span><br><span class="line"><span class="meta">nifi.cluster.node.address</span>=<span class="string"></span></span><br><span class="line"><span class="meta">nifi.cluster.node.protocol.port</span>=<span class="string"></span></span><br><span class="line"><span class="meta">nifi.cluster.node.protocol.threads</span>=<span class="string">10</span></span><br><span class="line"><span class="meta">nifi.cluster.node.protocol.max.threads</span>=<span class="string">50</span></span><br><span class="line"><span class="meta">nifi.cluster.node.event.history.size</span>=<span class="string">25</span></span><br><span class="line"><span class="meta">nifi.cluster.node.connection.timeout</span>=<span class="string">5 sec</span></span><br><span class="line"><span class="meta">nifi.cluster.node.read.timeout</span>=<span class="string">5 sec</span></span><br><span class="line"><span class="meta">nifi.cluster.node.max.concurrent.requests</span>=<span class="string">100</span></span><br><span class="line"><span class="meta">nifi.cluster.firewall.file</span>=<span class="string"></span></span><br><span class="line"><span class="meta">nifi.cluster.flow.election.max.wait.time</span>=<span class="string">5 mins</span></span><br><span class="line"><span class="meta">nifi.cluster.flow.election.max.candidates</span>=<span class="string"></span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"># cluster load balancing properties #</span></span><br><span class="line"><span class="meta">nifi.cluster.load.balance.host</span>=<span class="string"></span></span><br><span class="line"><span class="meta">nifi.cluster.load.balance.port</span>=<span class="string">6342</span></span><br><span class="line"><span class="meta">nifi.cluster.load.balance.connections.per.node</span>=<span class="string">4</span></span><br><span class="line"><span class="meta">nifi.cluster.load.balance.max.thread.count</span>=<span class="string">8</span></span><br><span class="line"><span class="meta">nifi.cluster.load.balance.comms.timeout</span>=<span class="string">30 sec</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"># zookeeper properties, used for cluster management #</span></span><br><span class="line"><span class="meta">nifi.zookeeper.connect.string</span>=<span class="string"></span></span><br><span class="line"><span class="meta">nifi.zookeeper.connect.timeout</span>=<span class="string">3 secs</span></span><br><span class="line"><span class="meta">nifi.zookeeper.session.timeout</span>=<span class="string">3 secs</span></span><br><span class="line"><span class="meta">nifi.zookeeper.root.node</span>=<span class="string">/nifi</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"># Zookeeper properties for the authentication scheme used when creating acls on znodes used for cluster management</span></span><br><span class="line"><span class="comment"># Values supported for nifi.zookeeper.auth.type are &quot;default&quot;, which will apply world/anyone rights on znodes</span></span><br><span class="line"><span class="comment"># and &quot;sasl&quot; which will give rights to the sasl/kerberos identity used to authenticate the nifi node</span></span><br><span class="line"><span class="comment"># The identity is determined using the value in nifi.kerberos.service.principal and the removeHostFromPrincipal</span></span><br><span class="line"><span class="comment"># and removeRealmFromPrincipal values (which should align with the kerberos.removeHostFromPrincipal and kerberos.removeRealmFromPrincipal</span></span><br><span class="line"><span class="comment"># values configured on the zookeeper server).</span></span><br><span class="line"><span class="meta">nifi.zookeeper.auth.type</span>=<span class="string"></span></span><br><span class="line"><span class="meta">nifi.zookeeper.kerberos.removeHostFromPrincipal</span>=<span class="string"></span></span><br><span class="line"><span class="meta">nifi.zookeeper.kerberos.removeRealmFromPrincipal</span>=<span class="string"></span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"># kerberos #</span></span><br><span class="line"><span class="meta">nifi.kerberos.krb5.file</span>=<span class="string"></span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"># kerberos service principal #</span></span><br><span class="line"><span class="meta">nifi.kerberos.service.principal</span>=<span class="string"></span></span><br><span class="line"><span class="meta">nifi.kerberos.service.keytab.location</span>=<span class="string"></span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"># kerberos spnego principal #</span></span><br><span class="line"><span class="meta">nifi.kerberos.spnego.principal</span>=<span class="string"></span></span><br><span class="line"><span class="meta">nifi.kerberos.spnego.keytab.location</span>=<span class="string"></span></span><br><span class="line"><span class="meta">nifi.kerberos.spnego.authentication.expiration</span>=<span class="string">12 hours</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"># external properties files for variable registry</span></span><br><span class="line"><span class="comment"># supports a comma delimited list of file locations</span></span><br><span class="line"><span class="meta">nifi.variable.registry.properties</span>=<span class="string"></span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>nifi.web.http.port=8080 —&gt; nifi.web.http.port=5800</p>
<blockquote>
<p>启动Nifi</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">bin/nifi.sh start</span><br></pre></td></tr></table></figure>

<blockquote>
<p>查看页面</p>
</blockquote>
<p><a href="http://127.0.0.1:5800/nifi/">http://127.0.0.1:5800/nifi/</a></p>
<p><img src="https://techyang-blog-pic.oss-cn-beijing.aliyuncs.com/img/image-20240908091509403.png" alt="image-20240908091509403"></p>
]]></content>
      <categories>
        <category>JAVA</category>
      </categories>
      <tags>
        <tag>Nifi 安装部署</tag>
      </tags>
  </entry>
  <entry>
    <title>从零到一搭建离线数仓之采集篇</title>
    <url>/techyang/2024/09/07/%E4%BB%8E%E9%9B%B6%E5%88%B0%E4%B8%80%E6%90%AD%E5%BB%BA%E7%A6%BB%E7%BA%BF%E6%95%B0%E4%BB%93%E4%B9%8B%E9%87%87%E9%9B%86%E7%AF%87/</url>
    <content><![CDATA[<ul>
<li><p>前置工作:服务器间的免密已完成.</p>
</li>
<li><p>安装常用工具包</p>
</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">yum install -y epel-release</span><br><span class="line">yum install -y net-tools vim psmisc  nc  rsync  lrzsz  ntp libzstd openssl-static iotop pdsh</span><br></pre></td></tr></table></figure>

<ul>
<li>编写分发脚本</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#!/bin/bash</span><br><span class="line"> </span><br><span class="line">#1. 判断参数个数</span><br><span class="line">if [ $# -lt 1 ]</span><br><span class="line">then</span><br><span class="line">  echo Not Enough Arguement!</span><br><span class="line">  exit;</span><br><span class="line">fi</span><br><span class="line"> </span><br><span class="line">#2. 遍历集群所有机器</span><br><span class="line">for host in bigdata101 bigdata102 bigdata103 bigdata104 bigdata105</span><br><span class="line">do</span><br><span class="line">  echo ====================  $host  ====================</span><br><span class="line">  #3. 遍历所有目录，挨个发送</span><br><span class="line">  for file in $@</span><br><span class="line">  do</span><br><span class="line">    #4 判断文件是否存在</span><br><span class="line">    if [ -e $file ]</span><br><span class="line">    then</span><br><span class="line">      #5. 获取父目录</span><br><span class="line">      pdir=$(cd -P $(dirname $file); pwd)</span><br><span class="line">      #6. 获取当前文件的名称</span><br><span class="line">      fname=$(basename $file)</span><br><span class="line">      ssh $host &quot;mkdir -p $pdir&quot;</span><br><span class="line">      rsync -av $pdir/$fname $host:$pdir</span><br><span class="line">    else</span><br><span class="line">      echo $file does not exists!</span><br><span class="line">    fi</span><br><span class="line">  done</span><br><span class="line">done</span><br></pre></td></tr></table></figure>

<p>优化版(可以指定分发的机器)</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#1. 判断参数个数</span></span><br><span class="line"><span class="keyword">if</span> [ <span class="variable">$#</span> -lt 2 ]</span><br><span class="line"><span class="keyword">then</span></span><br><span class="line">  <span class="built_in">echo</span> Not Enough Arguement!</span><br><span class="line">  <span class="built_in">exit</span>;</span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化变量</span></span><br><span class="line">hosts=()</span><br><span class="line">directories=()</span><br><span class="line">separator=0</span><br><span class="line"></span><br><span class="line"><span class="comment"># 遍历所有参数</span></span><br><span class="line"><span class="keyword">for</span> arg <span class="keyword">in</span> <span class="string">&quot;<span class="variable">$@</span>&quot;</span></span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">  <span class="keyword">if</span> [[ -d <span class="string">&quot;<span class="variable">$arg</span>&quot;</span> ]]; <span class="keyword">then</span></span><br><span class="line">      separator=1</span><br><span class="line">  <span class="keyword">fi</span></span><br><span class="line">  <span class="keyword">if</span> [[ -f <span class="string">&quot;<span class="variable">$arg</span>&quot;</span> ]]; <span class="keyword">then</span></span><br><span class="line">      separator=1</span><br><span class="line">  <span class="keyword">fi</span></span><br><span class="line">  <span class="keyword">if</span> [[ <span class="variable">$separator</span> -eq 0 ]]; <span class="keyword">then</span></span><br><span class="line">      hosts+=(<span class="string">&quot;<span class="variable">$arg</span>&quot;</span>)</span><br><span class="line">  <span class="keyword">else</span></span><br><span class="line">      directories+=(<span class="string">&quot;<span class="variable">$arg</span>&quot;</span>)</span><br><span class="line">  <span class="keyword">fi</span></span><br><span class="line"><span class="keyword">done</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#2. 遍历集群所有机器</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="string">&quot;<span class="variable">$&#123;!hosts[@]&#125;</span>&quot;</span></span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">  host=<span class="variable">$&#123;hosts[$i]&#125;</span></span><br><span class="line">  <span class="built_in">echo</span> ====================  <span class="variable">$host</span>  ====================</span><br><span class="line">  <span class="comment">#3. 遍历所有目录，挨个发送</span></span><br><span class="line">  <span class="keyword">for</span> j <span class="keyword">in</span> <span class="string">&quot;<span class="variable">$&#123;!directories[@]&#125;</span>&quot;</span></span><br><span class="line">  <span class="keyword">do</span></span><br><span class="line">    file=<span class="variable">$&#123;directories[$j]&#125;</span></span><br><span class="line">    <span class="comment">#4 判断文件是否存在</span></span><br><span class="line">    <span class="keyword">if</span> [ -e <span class="variable">$file</span> ]</span><br><span class="line">    <span class="keyword">then</span></span><br><span class="line">      <span class="comment">#5. 获取父目录</span></span><br><span class="line">      pdir=$(<span class="built_in">cd</span> -P $(dirname <span class="variable">$file</span>); <span class="built_in">pwd</span>)</span><br><span class="line">      <span class="comment">#6. 获取当前文件的名称</span></span><br><span class="line">      fname=$(basename <span class="variable">$file</span>)</span><br><span class="line">      ssh <span class="variable">$host</span> <span class="string">&quot;mkdir -p <span class="variable">$pdir</span>&quot;</span></span><br><span class="line">      rsync -av <span class="variable">$pdir</span>/<span class="variable">$fname</span> <span class="variable">$host</span>:<span class="variable">$pdir</span></span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">      <span class="built_in">echo</span> <span class="variable">$file</span> does not exists!</span><br><span class="line">    <span class="keyword">fi</span></span><br><span class="line">  <span class="keyword">done</span></span><br><span class="line"><span class="keyword">done</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h3 id="集群规划"><a href="#集群规划" class="headerlink" title="集群规划"></a>集群规划</h3><table>
<thead>
<tr>
<th>bigdata101</th>
<th>bigdata102</th>
<th>bigdata103</th>
<th>bigdata104</th>
<th>bigdata105</th>
</tr>
</thead>
<tbody><tr>
<td>JDK</td>
<td>JDK</td>
<td>JDK</td>
<td>JDK</td>
<td>JDK</td>
</tr>
<tr>
<td></td>
<td></td>
<td>ZK</td>
<td>ZK</td>
<td>ZK</td>
</tr>
<tr>
<td>NN</td>
<td>NN</td>
<td>DN</td>
<td>DN</td>
<td>DN</td>
</tr>
<tr>
<td>DFSZKFC</td>
<td>DFSZKFC</td>
<td>JN</td>
<td>JN</td>
<td>JN</td>
</tr>
<tr>
<td>RM</td>
<td>RM</td>
<td>NM</td>
<td>NM</td>
<td>NM</td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody></table>
<h3 id="安装JDK"><a href="#安装JDK" class="headerlink" title="安装JDK"></a>安装JDK</h3><ul>
<li><p>解压缩</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">tar -zxvf /opt/software/jdk-8u212-linux-x64.tar.gz -C /opt/module/</span><br></pre></td></tr></table></figure></li>
<li><p>配置环境变量</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo vim /etc/profile.d/my_env.sh</span><br></pre></td></tr></table></figure>

<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment">#JAVA_HOME</span></span><br><span class="line"><span class="built_in">export</span> JAVA_HOME=/opt/module/jdk1.8.0_212</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$JAVA_HOME</span>/bin</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">source /etc/profile.d/my_env.sh</span><br></pre></td></tr></table></figure></li>
<li><p>验证</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">java -version</span><br></pre></td></tr></table></figure>

<p>结果:</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">java version &quot;1.8.0_212&quot;</span><br><span class="line">Java(TM) SE Runtime Environment (build 1.8.0_212-b10)</span><br><span class="line">Java HotSpot(TM) 64-Bit Server VM (build 25.212-b10, mixed mode)</span><br></pre></td></tr></table></figure></li>
<li><p>分发</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">xsync /opt/module/jdk1.8.0_212</span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="安装ZK"><a href="#安装ZK" class="headerlink" title="安装ZK"></a>安装ZK</h3><ul>
<li><p>在bigdata3服务器解压缩</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">tar -zxvf /opt/software/apache-zookeeper-3.7.1-bin.tar.gz -C /opt/module</span><br></pre></td></tr></table></figure></li>
<li><p>重命名</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mv apache-zookeeper-3.7.1-bin zookeeper-3.7.1</span><br></pre></td></tr></table></figure></li>
<li><p>在zookeeper-3.7.1目录下创建zkData</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mkdir zkData</span><br></pre></td></tr></table></figure></li>
<li><p>在zkData创建文件myid</p>
<p>在文件中添加与server对应的编号（注意：上下不要有空行，左右不要有空格）</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">vim myid</span><br></pre></td></tr></table></figure>

<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">3</span><br></pre></td></tr></table></figure></li>
<li><p>在conf目录下复制一份zoo.cfg</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cp zoo_sample.cfg zoo.cfg</span><br></pre></td></tr></table></figure></li>
<li><p>修改zoo.cfg配置</p>
<p><img src="https://techyang-blog-pic.oss-cn-beijing.aliyuncs.com/img/image-20240907170155236.png" alt="image-20240907170155236"></p>
<p>配置参数解读:</p>
<p>server.A=B:C:D</p>
<p><strong>A</strong>是一个数字，表示这个是第几号服务器；</p>
<p>集群模式下配置一个文件myid，这个文件在dataDir目录下，这个文件里面有一个数据就是A的值，Zookeeper启动时读取此文件，拿到里面的数据与zoo.cfg里面的配置信息比较从而判断到底是哪个server。</p>
<p><strong>B</strong>是这个服务器的地址；</p>
<p><strong>C</strong>是这个服务器Follower与集群中的Leader服务器交换信息的端口；</p>
<p><strong>D</strong>是万一集群中的Leader服务器挂了，需要一个端口来重新进行选举，选出一个新的Leader，而这个端口就是用来执行选举时服务器相互通信的端口。</p>
</li>
<li><p>将bigdata3的zk分发到bigdata4,bigdata5并修改对应机器的myid</p>
</li>
<li><p>zk群起群停脚本</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">case</span> <span class="variable">$1</span> <span class="keyword">in</span></span><br><span class="line"><span class="string">&quot;start&quot;</span>)&#123;</span><br><span class="line">	<span class="keyword">for</span> i <span class="keyword">in</span> bigdata103 bigdata104 bigdata105</span><br><span class="line">	<span class="keyword">do</span></span><br><span class="line">        <span class="built_in">echo</span> ---------- zookeeper <span class="variable">$i</span> 启动 ------------</span><br><span class="line">		ssh <span class="variable">$i</span> <span class="string">&quot;/opt/module/zookeeper-3.7.1/bin/zkServer.sh start&quot;</span></span><br><span class="line">	<span class="keyword">done</span></span><br><span class="line">&#125;;;</span><br><span class="line"><span class="string">&quot;stop&quot;</span>)&#123;</span><br><span class="line">	<span class="keyword">for</span> i <span class="keyword">in</span> bigdata103 bigdata104 bigdata105</span><br><span class="line">	<span class="keyword">do</span></span><br><span class="line">        <span class="built_in">echo</span> ---------- zookeeper <span class="variable">$i</span> 停止 ------------    </span><br><span class="line">		ssh <span class="variable">$i</span> <span class="string">&quot;/opt/module/zookeeper-3.7.1/bin/zkServer.sh stop&quot;</span></span><br><span class="line">	<span class="keyword">done</span></span><br><span class="line">&#125;;;</span><br><span class="line"><span class="string">&quot;status&quot;</span>)&#123;</span><br><span class="line">	<span class="keyword">for</span> i <span class="keyword">in</span> bigdata103 bigdata104 bigdata105</span><br><span class="line">	<span class="keyword">do</span></span><br><span class="line">        <span class="built_in">echo</span> ---------- zookeeper <span class="variable">$i</span> 状态 ------------    </span><br><span class="line">		ssh <span class="variable">$i</span> <span class="string">&quot;/opt/module/zookeeper-3.7.1/bin/zkServer.sh status&quot;</span></span><br><span class="line">	<span class="keyword">done</span></span><br><span class="line">&#125;;;</span><br><span class="line"><span class="keyword">esac</span></span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="安装Hadoop"><a href="#安装Hadoop" class="headerlink" title="安装Hadoop"></a>安装Hadoop</h3><ul>
<li><p>在bigdata101解压缩</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">tar -zxvf /opt/software/hadoop-3.3.4.tar.gz -C /opt/module</span><br></pre></td></tr></table></figure></li>
<li><p>配置Hadoop环境变量</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="built_in">export</span> HADOOP_HOME=/opt/module/hadoop-3.3.4</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$HADOOP_HOME</span>/bin:<span class="variable">$HADOOP_HOME</span>/sbin</span><br></pre></td></tr></table></figure></li>
<li><p>调整./etc/hadoop/hadoop-env.sh</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment">#增加java环境变量</span></span><br><span class="line"><span class="built_in">export</span> JAVA_HOME=<span class="variable">$&#123;JAVA_HOME&#125;</span></span><br></pre></td></tr></table></figure></li>
<li><p>调整./etc/hadoop/core-site.xml</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;</span></span><br><span class="line"><span class="meta">&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;</span></span><br><span class="line"><span class="comment">&lt;!--</span></span><br><span class="line"><span class="comment">  Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span></span><br><span class="line"><span class="comment">  you may not use this file except in compliance with the License.</span></span><br><span class="line"><span class="comment">  You may obtain a copy of the License at</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">    http://www.apache.org/licenses/LICENSE-2.0</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">  Unless required by applicable law or agreed to in writing, software</span></span><br><span class="line"><span class="comment">  distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span></span><br><span class="line"><span class="comment">  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span></span><br><span class="line"><span class="comment">  See the License for the specific language governing permissions and</span></span><br><span class="line"><span class="comment">  limitations under the License. See accompanying LICENSE file.</span></span><br><span class="line"><span class="comment">--&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- Put site-specific property overrides in this file. --&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 指定NameNode的地址 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://mycluster<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 指定hadoop数据的存储目录 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.tmp.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>/opt/module/hadoop-3.3.4/data<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 配置HDFS网页登录使用的静态用户为qixy --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.http.staticuser.user<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>qixy<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 配置Zookeeper信息 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>ha.zookeeper.quorum<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>bigdata103:2181,bigdata104:2181,bigdata105:2181<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 配置该user(superUser)允许通过代理访问的主机节点 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.proxyuser.user.hosts<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>*<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 配置该user(superUser)允许通过代理用户所属组 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.proxyuser.user.groups<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>*<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 配置该user(superUser)允许通过代理的用户--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.proxyuser.user.users<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>*<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--  开启hdfs的垃圾桶机制，删除掉的数据可以从垃圾桶中回收，单位分钟 7天--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.trash.interval<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>1440<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure></li>
<li><p>调整./etc/hadoop/hdfs-site.xml</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;</span></span><br><span class="line"><span class="meta">&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;</span></span><br><span class="line"><span class="comment">&lt;!--</span></span><br><span class="line"><span class="comment">  Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span></span><br><span class="line"><span class="comment">  you may not use this file except in compliance with the License.</span></span><br><span class="line"><span class="comment">  You may obtain a copy of the License at</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">    http://www.apache.org/licenses/LICENSE-2.0</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">  Unless required by applicable law or agreed to in writing, software</span></span><br><span class="line"><span class="comment">  distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span></span><br><span class="line"><span class="comment">  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span></span><br><span class="line"><span class="comment">  See the License for the specific language governing permissions and</span></span><br><span class="line"><span class="comment">  limitations under the License. See accompanying LICENSE file.</span></span><br><span class="line"><span class="comment">--&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- Put site-specific property overrides in this file. --&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- NameNode数据存储目录 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.name.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>file://$&#123;hadoop.tmp.dir&#125;/name<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!-- DataNode数据存储目录 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.datanode.data.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>file://$&#123;hadoop.tmp.dir&#125;/data<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!-- JournalNode数据存储目录 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.journalnode.edits.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>$&#123;hadoop.tmp.dir&#125;/jn<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!-- 完全分布式集群名称 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.nameservices<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>mycluster<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!-- 集群中NameNode节点都有哪些 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.ha.namenodes.mycluster<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>nn1,nn2<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!-- NameNode的RPC通信地址 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.rpc-address.mycluster.nn1<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>bigdata101:8020<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.rpc-address.mycluster.nn2<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>bigdata102:8020<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!-- NameNode的http通信地址 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.http-address.mycluster.nn1<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>bigdata101:9870<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.http-address.mycluster.nn2<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>bigdata102:9870<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!-- 指定NameNode元数据在JournalNode上的存放位置 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.shared.edits.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>qjournal://bigdata103:8485;bigdata104:8485;bigdata105:8485/mycluster<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!-- 访问代理类：client用于确定哪个NameNode为Active --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.client.failover.proxy.provider.mycluster<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!-- 配置隔离机制，即同一时刻只能有一台服务器对外响应 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.ha.fencing.methods<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>sshfence<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!-- 使用隔离机制时需要ssh秘钥登录--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.ha.fencing.ssh.private-key-files<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>/home/qixy/.ssh/id_rsa<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 启用nn故障自动转移 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.ha.automatic-failover.enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure></li>
<li><p>配置DN节点</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">vim /opt/module/hadoop-3.3.4/etc/hadoop/workers</span><br></pre></td></tr></table></figure>

<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">bigdata101</span><br><span class="line">bigdata102</span><br><span class="line">bigdata103</span><br><span class="line">bigdata104</span><br><span class="line">bigdata105</span><br></pre></td></tr></table></figure></li>
<li><p>调整./etc/hadoop/yarn-site.xml</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=&quot;1.0&quot;?&gt;</span></span><br><span class="line"><span class="comment">&lt;!--</span></span><br><span class="line"><span class="comment">  Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span></span><br><span class="line"><span class="comment">  you may not use this file except in compliance with the License.</span></span><br><span class="line"><span class="comment">  You may obtain a copy of the License at</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">    http://www.apache.org/licenses/LICENSE-2.0</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">  Unless required by applicable law or agreed to in writing, software</span></span><br><span class="line"><span class="comment">  distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span></span><br><span class="line"><span class="comment">  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span></span><br><span class="line"><span class="comment">  See the License for the specific language governing permissions and</span></span><br><span class="line"><span class="comment">  limitations under the License. See accompanying LICENSE file.</span></span><br><span class="line"><span class="comment">--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- Site specific YARN configuration properties --&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- Site specific YARN configuration properties --&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 指定 MR 走 shuffle --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>mapreduce_shuffle<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services.mapreduce.shuffle.class<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>org.apache.hadoop.mapred.ShuffleHandler<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 日志聚集功能使用 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.log-aggregation-enable<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!-- 日志保留时间设置7天 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.log-aggregation.retain-seconds<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>604800<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!-- 日志聚合HDFS目录 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.remote-app-log-dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>/data/hadoop/yarn-logs<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!-- 超时的周期 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.connect.retry-interval.ms<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>2000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 启用resourcemanager ha --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.ha.enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!-- 声明两台resourcemanager的地址 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.cluster-id<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>cluster-yarn<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!--指定resourcemanager的逻辑列表--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.ha.rm-ids<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>rm1,rm2<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- ========== rm1的配置 ========== --&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 指定rm1的主机名 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.hostname.rm1<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>bigdata101<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!-- ========== rm2的配置 ========== --&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 指定rm2的主机名 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.hostname.rm2<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>bigdata102<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!-- 指定zookeeper集群的地址 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.zk-address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>bigdata103:2181,bigdata104:2181,bigdata105:2181<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!-- 启用自动恢复 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.recovery.enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!-- 指定resourcemanager的状态信息存储在zookeeper集群 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.store.class<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!-- 环境变量的继承 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.env-whitelist<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAPRED_HOME<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure></li>
<li><p>调整./etc/hadoop/mapred-site.xml</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=&quot;1.0&quot;?&gt;</span></span><br><span class="line"><span class="meta">&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;</span></span><br><span class="line"><span class="comment">&lt;!--</span></span><br><span class="line"><span class="comment">  Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span></span><br><span class="line"><span class="comment">  you may not use this file except in compliance with the License.</span></span><br><span class="line"><span class="comment">  You may obtain a copy of the License at</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">    http://www.apache.org/licenses/LICENSE-2.0</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">  Unless required by applicable law or agreed to in writing, software</span></span><br><span class="line"><span class="comment">  distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span></span><br><span class="line"><span class="comment">  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span></span><br><span class="line"><span class="comment">  See the License for the specific language governing permissions and</span></span><br><span class="line"><span class="comment">  limitations under the License. See accompanying LICENSE file.</span></span><br><span class="line"><span class="comment">--&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- Put site-specific property overrides in this file. --&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 指定MapReduce程序运行在Yarn上 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.framework.name<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>yarn<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>bigdata101:10020<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.webapp.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>bigdata101:19888<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure></li>
<li><p>分发hadoop文件和环境变量</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">xsync /opt/module/hadoop-3.3.4</span><br></pre></td></tr></table></figure></li>
<li><p>初始化集群</p>
<p>删除错误数据</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">xcall rm -rf /opt/module/hadoop-3.3.4/data /opt/module/hadoop-3.3.4/logs</span><br></pre></td></tr></table></figure>

<p>启动JN</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">xcall -w &quot;bigdata103,bigdata104,bigdata105&quot; &#x27;hdfs --daemon start journalnode&#x27;</span><br></pre></td></tr></table></figure>

<p>初始化其中一台NN</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">xcall -w &#x27;bigdata101&#x27; &#x27;hdfs namenode -format&#x27;</span><br></pre></td></tr></table></figure>

<p>启动初始化的NN</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">xcall -w &#x27;bigdata101&#x27; &#x27;hdfs --daemon start namenode&#x27;</span><br></pre></td></tr></table></figure>

<p>同步NN到其它节点的NN</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">xcall -w &#x27;bigdata102&#x27; &#x27;hdfs namenode -bootstrapStandby&#x27;</span><br></pre></td></tr></table></figure>

<p>启动其它节点NN</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">xcall -w &#x27;bigdata102&#x27; &#x27;hdfs --daemon start namenode&#x27;</span><br></pre></td></tr></table></figure>

<p>启动ZK</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">zk.sh start</span><br></pre></td></tr></table></figure>

<p>格式化ZKFC</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">hdfs zkfc -formatZK</span><br></pre></td></tr></table></figure>

<p>启动ZKFC</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">xcall -w &#x27;bigdata101,bigdata102&#x27; &#x27;hdfs --daemon start zkfc&#x27;</span><br></pre></td></tr></table></figure>

<p>启动DN</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">hdfs --workers --daemon start datanode</span><br></pre></td></tr></table></figure>

<p>启动yarn</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">start-yarn.sh</span><br></pre></td></tr></table></figure></li>
<li><p>编写hadoop启动脚本</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="meta">#! /bin/bash</span></span><br><span class="line"><span class="keyword">if</span> [ <span class="variable">$#</span> -eq 0 ]</span><br><span class="line"><span class="keyword">then</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">&quot;没有参数,请输入&quot;</span></span><br><span class="line">        <span class="built_in">exit</span></span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"><span class="keyword">case</span> <span class="variable">$1</span> <span class="keyword">in</span></span><br><span class="line"><span class="string">&quot;start&quot;</span>)</span><br><span class="line">        <span class="built_in">echo</span> <span class="string">&quot;===========启动hdfs============&quot;</span></span><br><span class="line">         ssh bigdata101 <span class="string">&quot;/opt/module/hadoop-3.3.4/sbin/start-dfs.sh&quot;</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">&quot;===========启动yarn============&quot;</span></span><br><span class="line">         ssh bigdata101 <span class="string">&quot;/opt/module/hadoop-3.3.4/sbin/start-yarn.sh&quot;</span></span><br><span class="line">        ;;</span><br><span class="line"><span class="string">&quot;stop&quot;</span>)</span><br><span class="line">        <span class="built_in">echo</span> <span class="string">&quot;===========关闭yarn============&quot;</span></span><br><span class="line">        ssh bigdata101 <span class="string">&quot;/opt/module/hadoop-3.3.4/sbin/stop-yarn.sh&quot;</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">&quot;===========关闭hdfs============&quot;</span></span><br><span class="line">        ssh bigdata101 <span class="string">&quot;/opt/module/hadoop-3.3.4/sbin/stop-dfs.sh&quot;</span></span><br><span class="line">        ;;</span><br><span class="line">*)</span><br><span class="line">        <span class="built_in">echo</span> <span class="string">&quot;参数错误&quot;</span></span><br><span class="line">        ;;</span><br><span class="line"><span class="keyword">esac</span></span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="部署Kafka"><a href="#部署Kafka" class="headerlink" title="部署Kafka"></a>部署Kafka</h3><ul>
<li><p>在bigdata103解压缩</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">tar -zxvf /opt/software/kafka_2.12-3.3.1.tgz -C /opt/module/</span><br></pre></td></tr></table></figure></li>
<li><p>修改配置文件 cofig/server.properties</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">vim /opt/module/kafka_2.12-3.3.1/config/server.properties</span><br></pre></td></tr></table></figure>

<p>要出修改的参数</p>
<figure class="highlight properties"><table><tr><td class="code"><pre><span class="line"><span class="comment">#broker的全局唯一编号，不能重复，只能是数字。</span></span><br><span class="line"><span class="meta">broker.id</span>=<span class="string">3</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">#broker对外暴露的IP和端口 （每个节点单独配置）       </span></span><br><span class="line"><span class="meta">advertised.listeners</span>=<span class="string">PLAINTEXT://bigdata103:9092</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">#kafka运行日志(数据)存放的路径，路径不需要提前创建，kafka自动帮你创建，可以配置多个磁盘路径，路径与路径之间可以用&quot;，&quot;分隔</span></span><br><span class="line"><span class="meta">log.dirs</span>=<span class="string">/opt/module/kafka_2.12-3.3.1/datas</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">#配置连接Zookeeper集群地址（在zk根目录下创建/kafka，方便管理）</span></span><br><span class="line"><span class="meta">zookeeper.connect</span>=<span class="string">bigdata103:2181,bigdata104:2181,bigdata105:2181/kafka</span></span><br></pre></td></tr></table></figure></li>
<li><p>配置环境变量(三台)</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment">#KAFKA_HOME</span></span><br><span class="line"><span class="built_in">export</span> KAFKA_HOME=/opt/module/kafka_2.12-3.3.1</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$KAFKA_HOME</span>/bin</span><br></pre></td></tr></table></figure></li>
<li><p>分发到要部署的机器</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">xsync bigdata103 bigdata104 bigdata105 /opt/module/kafka_2.12-3.3.1</span><br></pre></td></tr></table></figure></li>
<li><p>调整每台机器上的 broker.id 和 advertised.listeners</p>
<figure class="highlight properties"><table><tr><td class="code"><pre><span class="line"><span class="comment">#bigdata104</span></span><br><span class="line"><span class="meta">broker.id</span>=<span class="string">4</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">#broker对外暴露的IP和端口 （每个节点单独配置）       </span></span><br><span class="line"><span class="meta">advertised.listeners</span>=<span class="string">PLAINTEXT://bigdata104:9092</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">#bigdata105</span></span><br><span class="line"><span class="meta">broker.id</span>=<span class="string">5</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">#broker对外暴露的IP和端口 （每个节点单独配置）       </span></span><br><span class="line"><span class="meta">advertised.listeners</span>=<span class="string">PLAINTEXT://bigdata105:9092</span></span><br></pre></td></tr></table></figure></li>
<li><p>启动脚本</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="meta">#! /bin/bash</span></span><br><span class="line"> </span><br><span class="line"><span class="keyword">case</span> <span class="variable">$1</span> <span class="keyword">in</span></span><br><span class="line"><span class="string">&quot;start&quot;</span>)&#123;</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> bigdata103 bigdata104 bigdata105</span><br><span class="line">    <span class="keyword">do</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">&quot; --------启动 <span class="variable">$i</span> Kafka-------&quot;</span></span><br><span class="line">        ssh <span class="variable">$i</span> <span class="string">&quot;/opt/module/kafka_2.12-3.3.1/bin/kafka-server-start.sh -daemon /opt/module/kafka_2.12-3.3.1/config/server.properties&quot;</span></span><br><span class="line">    <span class="keyword">done</span></span><br><span class="line">&#125;;;</span><br><span class="line"><span class="string">&quot;stop&quot;</span>)&#123;</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> bigdata103 bigdata104 bigdata105</span><br><span class="line">    <span class="keyword">do</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">&quot; --------停止 <span class="variable">$i</span> Kafka-------&quot;</span></span><br><span class="line">        ssh <span class="variable">$i</span> <span class="string">&quot;/opt/module/kafka_2.12-3.3.1/bin/kafka-server-stop.sh &quot;</span></span><br><span class="line">    <span class="keyword">done</span></span><br><span class="line">&#125;;;</span><br><span class="line"><span class="keyword">esac</span></span><br></pre></td></tr></table></figure></li>
<li><p>验证</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kf.sh start</span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="部署Flume"><a href="#部署Flume" class="headerlink" title="部署Flume"></a>部署Flume</h3><ul>
<li><p>在bigdata101解压缩</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">tar -zxvf /opt/software/apache-flume-1.10.1-bin.tar.gz -C /opt/module/</span><br></pre></td></tr></table></figure></li>
<li><p>重命名</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mv /opt/module/apache-flume-1.10.1-bin /opt/module/flume-1.10.1</span><br></pre></td></tr></table></figure></li>
<li><p>创建存放flume日志的文件夹</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mkdir /opt/module/flume-1.10.1/logs</span><br></pre></td></tr></table></figure></li>
<li><p>调整日志配置</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">vim ./config/log4j2.xml</span><br></pre></td></tr></table></figure>

<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 将.当前目录调整为新建的日志目录 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">Property</span> <span class="attr">name</span>=<span class="string">&quot;LOG_DIR&quot;</span>&gt;</span>/opt/module/flume-1.10.1/logs<span class="tag">&lt;/<span class="name">Property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 引入控制台输出，方便学习查看日志 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">Root</span> <span class="attr">level</span>=<span class="string">&quot;INFO&quot;</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">AppenderRef</span> <span class="attr">ref</span>=<span class="string">&quot;LogFile&quot;</span> /&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">AppenderRef</span> <span class="attr">ref</span>=<span class="string">&quot;Console&quot;</span> /&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">Root</span>&gt;</span></span><br></pre></td></tr></table></figure></li>
<li><p>设置环境变量</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment">#FLUME_HOME</span></span><br><span class="line"><span class="built_in">export</span> FLUME_HOME=/opt/module/flume-1.10.1</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$FLUME_HOME</span>/bin</span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="采集配置验证"><a href="#采集配置验证" class="headerlink" title="采集配置验证"></a>采集配置验证</h3><ul>
<li><p>创建文件夹</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 用于存放自定义的配置</span></span><br><span class="line">mkdir -p /opt/module/flume-1.10.1/job</span><br><span class="line"><span class="meta">#</span><span class="bash"> 用于存放追加的元数据文件</span></span><br><span class="line">mkdir -p /opt/module/flume-1.10.1/position</span><br></pre></td></tr></table></figure></li>
<li><p>在job路径下配置文件系统到kafka的配置文件(日志选择tailDirSource)</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 定义组件</span><br><span class="line">a1.sources = r1</span><br><span class="line">a1.channels = c1</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#source</span><br><span class="line">a1.sources.r1.type = TAILDIR</span><br><span class="line">a1.sources.r1.filegroups = f1</span><br><span class="line">a1.sources.r1.filegroups.f1 = /opt/module/applog/log/app.*</span><br><span class="line">a1.sources.r1.positionFile = /opt/module/flume-1.10.1/position/taildir_position.json</span><br><span class="line"></span><br><span class="line">#channel</span><br><span class="line">a1.channels.c1.type = org.apache.flume.channel.kafka.KafkaChannel</span><br><span class="line">a1.channels.c1.kafka.bootstrap.servers = bigdata103:9092,bigdata104:9092,bigdata105:9092</span><br><span class="line">a1.channels.c1.kafka.topic = topic_log</span><br><span class="line">#parseAsFlumeEvent设置为false，到kafka的内容就只包含body的了，不包含头的了</span><br><span class="line">a1.channels.c1.parseAsFlumeEvent = false</span><br><span class="line"></span><br><span class="line"># bind</span><br><span class="line">a1.sources.r1.channels = c1</span><br></pre></td></tr></table></figure></li>
<li><p>验证本地文件到Kafka的通道是否打通</p>
<blockquote>
<p>前提保证zk,kafka已启动</p>
</blockquote>
<p>启动Flume</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">flume-ng agent -c /opt/module/flume-1.10.1/conf -f /opt/module/flume-1.10.1/job/log_to_kafka.conf -n a1</span><br></pre></td></tr></table></figure>

<p>开启Kafka消费者</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kafka-console-consumer.sh --bootstrap-server bigdata103:9092 --topic topic_log</span><br></pre></td></tr></table></figure>

<p>模拟日志数据</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">java -jar gmall-remake-mock-2023-05-15-3.jar test 100</span><br></pre></td></tr></table></figure>

<p>如果看到消费者消费到了日志数据,说明通道打通.</p>
<p><img src="https://techyang-blog-pic.oss-cn-beijing.aliyuncs.com/img/image-20240908155952188.png" alt="image-20240908155952188"></p>
</li>
<li><p>封装flume启动脚本</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">!/bin/bash</span></span><br><span class="line"></span><br><span class="line">case $1 in</span><br><span class="line">&quot;start&quot;)&#123;</span><br><span class="line">    echo &quot; --------启动 bigdata101 采集flume-------&quot;</span><br><span class="line">    ssh bigdata101 &quot;nohup /opt/module/flume-1.10.1/bin/flume-ng agent -n a1 -c /opt/module/flume-1.10.1/conf/ -f /opt/module/flume-1.10.1/job/log_to_kafka.conf &gt;/dev/null 2&gt;&amp;1 &amp;&quot;</span><br><span class="line">&#125;;;</span><br><span class="line">&quot;stop&quot;)&#123;</span><br><span class="line">    echo &quot; --------停止 bigdata101 采集flume-------&quot;</span><br><span class="line">    ssh bigdata101 &quot;ps -ef | grep log_to_kafka | grep -v grep |awk  &#x27;&#123;print \$2&#125;&#x27; | xargs -n1 kill -9 &quot;</span><br><span class="line">&#125;;;</span><br><span class="line">esac</span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="安装MySQL"><a href="#安装MySQL" class="headerlink" title="安装MySQL"></a>安装MySQL</h3><ul>
<li><p>卸载MySQL依赖</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo yum remove mysql-libs</span><br></pre></td></tr></table></figure></li>
<li><p>安装依赖</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo yum install libaio</span><br><span class="line"></span><br><span class="line">sudo yum -y install autoconf</span><br></pre></td></tr></table></figure></li>
<li><p>切换root用户,执行安装脚本</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">su root</span><br><span class="line"></span><br><span class="line">sh install_mysql.sh</span><br></pre></td></tr></table></figure></li>
<li><p>切回普通用户</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">exit</span><br></pre></td></tr></table></figure></li>
</ul>
]]></content>
      <categories>
        <category>JAVA</category>
      </categories>
      <tags>
        <tag>离线数仓</tag>
      </tags>
  </entry>
</search>
